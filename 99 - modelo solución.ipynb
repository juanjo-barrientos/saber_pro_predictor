{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a2f3f08",
   "metadata": {},
   "source": [
    "# LigthGBM con feature engineering\n",
    "\n",
    "Para la entrega final y despues de haber hecho varias pruebas con diferentes modelos se decidio usar este modelo junto con una estrategia de feature engineering, a modo de garantizar una separabildad mayor para las variables respuesta medio-alto y medio-bajo y mayor numero de datos que amplien la interpretabilidad de los datos.\n",
    "\n",
    "Este modelo se selecciono gracias a ser el que muestra mejor rendimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d253ade4",
   "metadata": {},
   "source": [
    "<h2>Importaciones importantes y reproducibilidad</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ab1800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JUANJO\\Documents\\UdeA\\saber_pro_predictor\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]\n",
      "pandas: 2.3.3\n",
      "numpy: 2.3.3\n",
      "lightgbm: 4.6.0\n",
      "shap: 0.50.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm.callback import early_stopping, log_evaluation\n",
    "\n",
    "# opcionales para explainability\n",
    "import shap\n",
    "\n",
    "RND = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(RND)\n",
    "random.seed(RND)\n",
    "np.random.seed(RND)\n",
    "\n",
    "print(\"Python:\", sys.version.splitlines()[0])\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"lightgbm:\", lgb.__version__)\n",
    "print(\"shap:\", getattr(shap, '__version__', 'not installed'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0adace",
   "metadata": {},
   "source": [
    "Esta funcion de pre procesamiento usa los mismos maps y parametros que los usados en el notebook \"02 - prprocesado.ipynb\", todos estos parametros se cargan desde un archivo .plk usando la libreria de joblib.\n",
    "\n",
    "Por otra parte, tambien se asegura que se extraen los valores de la columna \"ID\" ya que será importante despues para la submision y se eliminaran las mismas columnas que se eliminaron en la anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01cf72f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_new(df, params_path='data/preproc_params.pkl', one_hot_target=True, inplace=False):\n",
    "    params = joblib.load(params_path)\n",
    "    df = df if inplace else df.copy()\n",
    "\n",
    "    for c in params.get('cols_to_drop', []):\n",
    "        if c in df.columns:\n",
    "            df.drop(columns=[c], inplace=True)\n",
    "\n",
    "    if 'F_TIENEINTERNET.1' in df.columns:\n",
    "        df.drop(columns=['F_TIENEINTERNET.1'], inplace=True)\n",
    "\n",
    "    ordinal_maps = params.get('ordinal_mappings', {})\n",
    "    for var, mapping in ordinal_maps.items():\n",
    "        if var not in df.columns:\n",
    "            continue\n",
    "        df[var] = df[var].map(mapping)\n",
    "        df[var] = df[var].where(pd.notna(df[var]), other=pd.NA)\n",
    "        try:\n",
    "            df[var] = df[var].astype('Int64')\n",
    "        except Exception:\n",
    "            df[var] = pd.to_numeric(df[var], errors='coerce').where(pd.notna(df[var]), pd.NA).astype('Int64')\n",
    "\n",
    "    binary_maps = params.get('binary_maps', {})\n",
    "    for col, mapping in binary_maps.items():\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].map(mapping)\n",
    "            df[col] = df[col].where(pd.notna(df[col]), other=pd.NA).astype('Int64')\n",
    "\n",
    "    enc_prg = params.get('E_PRGM_ACADEMICO_ENC_map', {})\n",
    "    enc_dep = params.get('E_PRGM_DEPARTAMENTO_ENC_map', {})\n",
    "    global_mean = params.get('global_mean', np.nan)\n",
    "\n",
    "    if 'E_PRGM_ACADEMICO' in df.columns:\n",
    "        df['E_PRGM_ACADEMICO_ENC'] = df['E_PRGM_ACADEMICO'].map(enc_prg)\n",
    "        df['E_PRGM_ACADEMICO_ENC'].fillna(global_mean, inplace=True)\n",
    "        df.drop(columns=['E_PRGM_ACADEMICO'], inplace=True)\n",
    "\n",
    "    if 'E_PRGM_DEPARTAMENTO' in df.columns:\n",
    "        df['E_PRGM_DEPARTAMENTO_ENC'] = df['E_PRGM_DEPARTAMENTO'].map(enc_dep)\n",
    "        df['E_PRGM_DEPARTAMENTO_ENC'].fillna(global_mean, inplace=True)\n",
    "        df.drop(columns=['E_PRGM_DEPARTAMENTO'], inplace=True)\n",
    "\n",
    "    fill_values = params.get('fill_values', {})\n",
    "    for col, info in fill_values.items():\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        strat = info.get('strategy', None)\n",
    "        val = info.get('value', None)\n",
    "\n",
    "        if strat in ('mean', 'mean_coerced', 'mean_rounded', 'mode', 'mode_fallback_non_numeric'):\n",
    "            if pd.isna(val) or val is None:\n",
    "                if strat.startswith('mean'):\n",
    "                    fill_val = df[col].mean(skipna=True)\n",
    "                else:\n",
    "                    mode_series = df[col].mode(dropna=True)\n",
    "                    fill_val = mode_series.iloc[0] if len(mode_series) > 0 else pd.NA\n",
    "            else:\n",
    "                fill_val = val\n",
    "            df[col].fillna(fill_val, inplace=True)\n",
    "            if strat == 'mean_rounded':\n",
    "                try:\n",
    "                    df[col] = df[col].round().astype('Int64')\n",
    "                except Exception:\n",
    "                    pass\n",
    "        elif strat == 'mode' and val is None:\n",
    "            mode_series = df[col].mode(dropna=True)\n",
    "            if len(mode_series) > 0:\n",
    "                df[col].fillna(mode_series.iloc[0], inplace=True)\n",
    "        else:\n",
    "            if not (pd.isna(val) or val is None):\n",
    "                df[col].fillna(val, inplace=True)\n",
    "\n",
    "    scale_params = params.get('scale_params', {})\n",
    "    cols_to_scale = [c for c in params.get('cols_to_scale', []) if c in df.columns]\n",
    "    for c in cols_to_scale:\n",
    "        mn_mx = scale_params.get(c, None)\n",
    "        if mn_mx is None:\n",
    "            col_min = df[c].min(skipna=True)\n",
    "            col_max = df[c].max(skipna=True)\n",
    "        else:\n",
    "            try:\n",
    "                col_min, col_max = float(mn_mx[0]), float(mn_mx[1])\n",
    "            except Exception:\n",
    "                col_min = df[c].min(skipna=True)\n",
    "                col_max = df[c].max(skipna=True)\n",
    "\n",
    "        if pd.isna(col_min) or pd.isna(col_max) or col_max == col_min:\n",
    "            continue\n",
    "        df[c] = (df[c] - col_min) / (col_max - col_min)\n",
    "        df[c] = df[c].clip(0.0, 1.0)\n",
    "\n",
    "    ids = df[\"ID\"]\n",
    "    df.drop(columns=[\"ID\"], inplace=True)\n",
    "    X = df.copy()\n",
    "    return X, ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6de18b",
   "metadata": {},
   "source": [
    "### 2. Se cargan los archivos necesarios para entrenar el modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3f5a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw shapes: (690861, 17) (690861, 1) (690861, 4)\n",
      "X_proc shape: (690861, 17) y_vec shape: (690861,)\n"
     ]
    }
   ],
   "source": [
    "preprocess_raw = False\n",
    "\n",
    "y_df = pd.read_csv('data/y_preprocessed.csv')            # preferible: etiqueta (n,1)\n",
    "y_onehot_df = pd.read_csv('data/y_one_hot_preprocessed.csv')  # one-hot (n,4)\n",
    "\n",
    "# Convertir y a vector 1D; priorizar y_df si está bien formado\n",
    "if y_df.shape[1] == 1:\n",
    "    y_vec = y_df.iloc[:,0].values\n",
    "else:\n",
    "    # fallback: derivar desde one-hot\n",
    "    y_vec = y_onehot_df.values.argmax(axis=1)\n",
    "\n",
    "if preprocess_raw:\n",
    "    X_raw = pd.read_csv('data/train.csv')\n",
    "    X_proc, ids = preprocess_new(X_raw, params_path='data/preproc_params.pkl', inplace=False)\n",
    "else:\n",
    "    X_raw = pd.read_csv('data/X_preprocessed.csv')\n",
    "    X_proc = X_raw.copy()\n",
    "    \n",
    "print(\"raw shapes:\", X_raw.shape, y_df.shape, y_onehot_df.shape)\n",
    "print(\"X_proc shape:\", X_proc.shape, \"y_vec shape:\", y_vec.shape)\n",
    "\n",
    "# Eliminar columnas que NO deben usarse\n",
    "for drop_col in ['ID','F_PRIVADOLIBERTAD','F_INTERNET1']:\n",
    "    if drop_col in X_proc.columns:\n",
    "        X_proc.drop(columns=[drop_col], inplace=True)\n",
    "        print(\"Dropped column:\", drop_col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf13f018",
   "metadata": {},
   "source": [
    "### 3. Se define la funcion de feature enginnering haciendo uso de las siguientes ideas:\n",
    "\n",
    "- K-Fold target-mean encoding (OUT-OF-FOLD) para E_PRGM_ACADEMICO y E_PRGM_DEPARTAMENTO\n",
    "- Estadísticas por grupo (mean/std/count) — por programa/dep sobre INDICADOR\n",
    "- Frequency encoding para categorías de alta cardinalidad\n",
    "- Binning (ordinalización) y flags para E_VALORMATRICULAUNIVERSIDAD y E_HORASSEMANATRABAJA\n",
    "- Interacciones (producto / ratio) relevantes\n",
    "- Missing indicator flags (la ausencia de información (no reportar matrícula, no reportar educación de padres) puede ser predictiva)\n",
    "- Clustering sobre indicadores (k-means) → cluster id como feature\n",
    "- Cross feature program x estrato\n",
    "- Label encode program for potential NN embeddings\n",
    "\n",
    "Todo esto resulta en un aumento de dimensiones hasta 41 columnas/variables diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092ec9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def kfold_target_mean_series(X, y, col, n_splits=5, seed=RND):\n",
    "    \"\"\"Produce OOF target mean encoding as pd.Series aligned to X.index\"\"\"\n",
    "    y_arr = np.asarray(y).ravel()\n",
    "    out = pd.Series(index=X.index, dtype=float)\n",
    "    gm = np.nanmean(y_arr.astype(float))\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    for tr_idx, val_idx in kf.split(X):\n",
    "        grp = pd.Series(y_arr[tr_idx]).groupby(X.iloc[tr_idx][col]).mean()\n",
    "        out.iloc[val_idx] = X.iloc[val_idx][col].map(grp)\n",
    "    out.fillna(gm, inplace=True)\n",
    "    return out\n",
    "\n",
    "def freq_encode_series(X, col):\n",
    "    vc = X[col].value_counts()\n",
    "    return X[col].map(vc).fillna(0)\n",
    "\n",
    "def feature_engineer(X, y=None, do_kmeans=True, kmeans_k=8, save_maps_path='data/fe_maps.pkl'):\n",
    "    \"\"\"\n",
    "    Aplica transformaciones y devuelve X_fe (DataFrame) y un dict 'saved' con maps/models.\n",
    "    \"\"\"\n",
    "    X = X.copy()\n",
    "    saved = {}\n",
    "\n",
    "    # 1) Missing flags\n",
    "    for c in X.columns:\n",
    "        if X[c].isna().any():\n",
    "            X[c + '_isna'] = X[c].isna().astype(int)\n",
    "\n",
    "    # 2) Binning matricula y horas (ajustar bins si hace falta)\n",
    "    if 'E_VALORMATRICULAUNIVERSIDAD' in X.columns:\n",
    "        X['matricula_bin'] = pd.cut(X['E_VALORMATRICULAUNIVERSIDAD'].fillna(-1),\n",
    "                                     bins=[-1,0,1,2,3,4,5,6,10], labels=False)\n",
    "    if 'E_HORASSEMANATRABAJA' in X.columns:\n",
    "        X['horas_bin'] = pd.cut(X['E_HORASSEMANATRABAJA'].fillna(-1),\n",
    "                                 bins=[-1,0,1,2,3,4,10], labels=False)\n",
    "\n",
    "    # 3) Interactions\n",
    "    if {'E_HORASSEMANATRABAJA','INDICADOR_1'}.issubset(X.columns):\n",
    "        X['hours_x_ind1'] = X['E_HORASSEMANATRABAJA'].fillna(0) * X['INDICADOR_1'].fillna(0)\n",
    "    if {'E_VALORMATRICULAUNIVERSIDAD','F_ESTRATOVIVIENDA'}.issubset(X.columns):\n",
    "        X['matric_x_estrato'] = X['E_VALORMATRICULAUNIVERSIDAD'].fillna(0) * X['F_ESTRATOVIVIENDA'].fillna(0)\n",
    "\n",
    "    # 4) Frequency encoding program & department\n",
    "    if 'E_PRGM_ACADEMICO_ENC' in X.columns:\n",
    "        prg_freq = X['E_PRGM_ACADEMICO_ENC'].value_counts()\n",
    "        X['prg_freq'] = X['E_PRGM_ACADEMICO_ENC'].map(prg_freq).fillna(0)\n",
    "        saved['prg_freq_map'] = prg_freq.to_dict()\n",
    "    if 'E_PRGM_DEPARTAMENTO_ENC' in X.columns:\n",
    "        dep_freq = X['E_PRGM_DEPARTAMENTO_ENC'].value_counts()\n",
    "        X['dep_freq'] = X['E_PRGM_DEPARTAMENTO_ENC'].map(dep_freq).fillna(0)\n",
    "        saved['dep_freq_map'] = dep_freq.to_dict()\n",
    "\n",
    "    # 5) KFold target-mean enc (OOF) for program/dep (requires y)\n",
    "    if y is not None:\n",
    "        try:\n",
    "            if 'E_PRGM_ACADEMICO_ENC' in X.columns:\n",
    "                X['prg_tgt_mean'] = kfold_target_mean_series(X, y, 'E_PRGM_ACADEMICO_ENC', n_splits=5, seed=RND)\n",
    "            if 'E_PRGM_DEPARTAMENTO_ENC' in X.columns:\n",
    "                X['dep_tgt_mean'] = kfold_target_mean_series(X, y, 'E_PRGM_DEPARTAMENTO_ENC', n_splits=5, seed=RND)\n",
    "        except Exception as e:\n",
    "            print(\"Warning: target-mean encoding failed:\", e)\n",
    "\n",
    "    # 6) Aggregates by program (indicator means/std/count)\n",
    "    agg_cols = [c for c in ['INDICADOR_1','INDICADOR_2','INDICADOR_3','INDICADOR_4'] if c in X.columns]\n",
    "    if 'E_PRGM_ACADEMICO_ENC' in X.columns and len(agg_cols)>0:\n",
    "        agg = X.groupby('E_PRGM_ACADEMICO_ENC')[agg_cols].agg(['mean','std','count'])\n",
    "        agg.columns = ['_'.join(col).strip() for col in agg.columns.values]\n",
    "        # merge (map)\n",
    "        for col in agg.columns:\n",
    "            X[f'prg_{col}'] = X['E_PRGM_ACADEMICO_ENC'].map(agg[col]).fillna(0)\n",
    "        saved['prg_agg_map'] = agg\n",
    "\n",
    "    # 7) KMeans clustering on indicators\n",
    "    if do_kmeans and len(agg_cols) >= 2:\n",
    "        km = KMeans(n_clusters=kmeans_k, random_state=RND)\n",
    "        X['cluster_indic'] = km.fit_predict(X[agg_cols].fillna(0))\n",
    "        saved['kmeans_model'] = km\n",
    "\n",
    "    # 8) Cross feature program x estrato\n",
    "    if {'E_PRGM_ACADEMICO_ENC','F_ESTRATOVIVIENDA'}.issubset(X.columns):\n",
    "        X['prg_estrato'] = X['E_PRGM_ACADEMICO_ENC'].astype(str) + '_' + X['F_ESTRATOVIVIENDA'].astype(str)\n",
    "        prg_estrato_freq = X['prg_estrato'].value_counts()\n",
    "        X['prg_estrato_freq'] = X['prg_estrato'].map(prg_estrato_freq).fillna(0)\n",
    "        saved['prg_estrato_freq_map'] = prg_estrato_freq.to_dict()\n",
    "\n",
    "    # 9) Label encode program for potential NN embeddings\n",
    "    if 'E_PRGM_ACADEMICO_ENC' in X.columns:\n",
    "        le = LabelEncoder()\n",
    "        X['prg_idx'] = le.fit_transform(X['E_PRGM_ACADEMICO_ENC'].astype(str).fillna('NA'))\n",
    "        saved['prg_label_encoder'] = le\n",
    "\n",
    "    # Save maps\n",
    "    if save_maps_path:\n",
    "        os.makedirs(os.path.dirname(save_maps_path), exist_ok=True)\n",
    "        joblib.dump(saved, save_maps_path)\n",
    "\n",
    "    return X, saved\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7158424",
   "metadata": {},
   "source": [
    "Se hace un mapeo de cada una de las variables hacia un valor numerico ordinal, de modo que el modelo logre comprender la estructura de las labels en una estructura de dato numerica ordinal (no funciona con one hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2c913b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo conversión de etiquetas:\n",
      "     original  numeric\n",
      "0  medio-alto        2\n",
      "1        bajo        0\n",
      "2        bajo        0\n",
      "3        alto        3\n",
      "4  medio-bajo        1\n",
      "X_fe shape: (690861, 41)\n"
     ]
    }
   ],
   "source": [
    "# Mapeo ordinal → numérico\n",
    "label_map = {\n",
    "    \"bajo\": 0,\n",
    "    \"medio-bajo\": 1,\n",
    "    \"medio-alto\": 2,\n",
    "    \"alto\": 3\n",
    "}\n",
    "\n",
    "y_numeric = y_df[\"RENDIMIENTO_GLOBAL\"].map(label_map).astype(int)\n",
    "print(\"Ejemplo conversión de etiquetas:\")\n",
    "print(pd.DataFrame({\"original\": y_vec, \"numeric\": y_numeric}).head())\n",
    "\n",
    "# Aplicar feature engineering\n",
    "X_fe, fe_maps = feature_engineer(\n",
    "    X_proc,\n",
    "    y=y_numeric,\n",
    "    do_kmeans=True,\n",
    "    kmeans_k=8,\n",
    "    save_maps_path=\"data/fe_maps.pkl\"\n",
    ")\n",
    "\n",
    "print(\"X_fe shape:\", X_fe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c01481",
   "metadata": {},
   "source": [
    "### Eliminamos las columnas que no queramos usar, separamos entre entrenamiento, test y validacion y nos aseguramos de que todas las estructuras de datos tengan el formato que especificamente queremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b021f4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all object columns to category → integer codes\n",
    "for col in X_proc.select_dtypes(include=[\"object\"]).columns:\n",
    "    X_proc[col] = X_proc[col].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "695190bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (621774, 41) (621774,) Test: (69087, 41) (69087,)\n"
     ]
    }
   ],
   "source": [
    "# Cell 6 — split (estratificado)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Excluir columnas que no queremos entrenar (por seguridad)\n",
    "for c in ['ID','F_PRIVADOLIBERTAD','F_INTERNET1']:\n",
    "    if c in X_fe.columns:\n",
    "        X_fe.drop(columns=[c], inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_fe, y_numeric, test_size=0.10, random_state=RND, stratify=y_numeric)\n",
    "print(\"Train:\", X_train.shape, y_train.shape, \"Test:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a34b9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_train.select_dtypes(include=[\"object\"]).columns:\n",
    "    X_train[col] = X_train[col].astype(\"category\").cat.codes\n",
    "\n",
    "for col in X_test.select_dtypes(include=[\"object\"]).columns:\n",
    "    X_test[col] = X_test[col].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649d2508",
   "metadata": {},
   "source": [
    "### 4. Celda 16 — Entrenamiento CV con StratifiedKFold y LightGBM\n",
    "- Objetivo: hacer validación cruzada estratificada (5 folds) sobre X_train/y_train para evaluar estabilidad del modelo y obtener métricas por fold.\n",
    "- Preparación:\n",
    "    - Se resetean índices de X_train y y_train para evitar problemas al indexar.\n",
    "    - Se crea un `StratifiedKFold(n_splits=5, shuffle=True, random_state=RND)` para mantener la proporción de clases en cada fold.\n",
    "- Bucle por fold:\n",
    "    - Se obtienen índices de entrenamiento/validación y se seleccionan con `iloc` (evita KeyError por índices no coincidentes).\n",
    "    - Se instancia un `lgb.LGBMClassifier` con hiperparámetros fijos (multiclass, learning_rate 0.03, num_leaves 64, regularización, etc.).\n",
    "    - Se entrena con `fit(..., eval_set=[(X_val,y_val)], eval_metric=\"multi_logloss\", callbacks=[log_evaluation(period=100), early_stopping(80)])` para usar evaluación en validación y early stopping.\n",
    "    - Se predice sobre la partición de validación y se calculan accuracy, macro-F1 y la matriz de confusión. Se acumulan métricas y modelos.\n",
    "- Resultados:\n",
    "    - Lista `accs` y `f1s` por fold, `cm_sum` con la suma agregada de las matrices de confusión, `models` contiene un modelo por fold.\n",
    "    - Se imprime resumen de resultados (media y desviación)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edaab7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1 training ---\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's multi_logloss: 1.20187\n",
      "[200]\tvalid_0's multi_logloss: 1.1904\n",
      "[300]\tvalid_0's multi_logloss: 1.18732\n",
      "[400]\tvalid_0's multi_logloss: 1.18627\n",
      "[500]\tvalid_0's multi_logloss: 1.18563\n",
      "[600]\tvalid_0's multi_logloss: 1.18522\n",
      "[700]\tvalid_0's multi_logloss: 1.18497\n",
      "[800]\tvalid_0's multi_logloss: 1.18483\n",
      "[900]\tvalid_0's multi_logloss: 1.18481\n",
      "Early stopping, best iteration is:\n",
      "[846]\tvalid_0's multi_logloss: 1.18477\n",
      "Fold 1 trained in 180.5s; best_iter=846\n",
      "Fold 1 Acc: 0.4422 Macro-F1: 0.4308\n",
      "\n",
      "--- Fold 2 training ---\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's multi_logloss: 1.2012\n",
      "[200]\tvalid_0's multi_logloss: 1.19015\n",
      "[300]\tvalid_0's multi_logloss: 1.18683\n",
      "[400]\tvalid_0's multi_logloss: 1.18588\n",
      "[500]\tvalid_0's multi_logloss: 1.18551\n",
      "[600]\tvalid_0's multi_logloss: 1.18535\n",
      "[700]\tvalid_0's multi_logloss: 1.18518\n",
      "[800]\tvalid_0's multi_logloss: 1.18516\n",
      "Early stopping, best iteration is:\n",
      "[810]\tvalid_0's multi_logloss: 1.18514\n",
      "Fold 2 trained in 204.7s; best_iter=810\n",
      "Fold 2 Acc: 0.4417 Macro-F1: 0.4301\n",
      "\n",
      "--- Fold 3 training ---\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's multi_logloss: 1.20282\n",
      "[200]\tvalid_0's multi_logloss: 1.19162\n",
      "[300]\tvalid_0's multi_logloss: 1.18816\n",
      "[400]\tvalid_0's multi_logloss: 1.18713\n",
      "[500]\tvalid_0's multi_logloss: 1.18667\n",
      "[600]\tvalid_0's multi_logloss: 1.18627\n",
      "[700]\tvalid_0's multi_logloss: 1.18618\n",
      "[800]\tvalid_0's multi_logloss: 1.18603\n",
      "[900]\tvalid_0's multi_logloss: 1.18584\n",
      "[1000]\tvalid_0's multi_logloss: 1.18568\n",
      "Early stopping, best iteration is:\n",
      "[997]\tvalid_0's multi_logloss: 1.18568\n",
      "Fold 3 trained in 245.1s; best_iter=997\n",
      "Fold 3 Acc: 0.4420 Macro-F1: 0.4309\n",
      "\n",
      "--- Fold 4 training ---\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's multi_logloss: 1.20263\n",
      "[200]\tvalid_0's multi_logloss: 1.19151\n",
      "[300]\tvalid_0's multi_logloss: 1.1885\n",
      "[400]\tvalid_0's multi_logloss: 1.1877\n",
      "[500]\tvalid_0's multi_logloss: 1.18722\n",
      "[600]\tvalid_0's multi_logloss: 1.18691\n",
      "[700]\tvalid_0's multi_logloss: 1.18663\n",
      "[800]\tvalid_0's multi_logloss: 1.18642\n",
      "[900]\tvalid_0's multi_logloss: 1.18638\n",
      "Early stopping, best iteration is:\n",
      "[886]\tvalid_0's multi_logloss: 1.18636\n",
      "Fold 4 trained in 187.0s; best_iter=886\n",
      "Fold 4 Acc: 0.4404 Macro-F1: 0.4287\n",
      "\n",
      "--- Fold 5 training ---\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's multi_logloss: 1.2036\n",
      "[200]\tvalid_0's multi_logloss: 1.19264\n",
      "[300]\tvalid_0's multi_logloss: 1.18989\n",
      "[400]\tvalid_0's multi_logloss: 1.18887\n",
      "[500]\tvalid_0's multi_logloss: 1.18832\n",
      "[600]\tvalid_0's multi_logloss: 1.1881\n",
      "[700]\tvalid_0's multi_logloss: 1.18785\n",
      "[800]\tvalid_0's multi_logloss: 1.18783\n",
      "[900]\tvalid_0's multi_logloss: 1.18785\n",
      "Early stopping, best iteration is:\n",
      "[849]\tvalid_0's multi_logloss: 1.18779\n",
      "Fold 5 trained in 271.0s; best_iter=849\n",
      "Fold 5 Acc: 0.4411 Macro-F1: 0.4298\n",
      "\n",
      "=== CV Results ===\n",
      "Accuracy per fold: [0.4422098025813196, 0.44171122994652406, 0.4420489726991275, 0.44040046640665836, 0.4411277482027116]\n",
      "Macro-F1 per fold: [0.43077604639023037, 0.43010338454044383, 0.43085785450686853, 0.42865320359743014, 0.42977433324437414]\n",
      "Mean Acc: 0.4415 (std 0.0007)\n",
      "Mean Macro-F1: 0.4300 (std 0.0008)\n",
      "Aggregated confusion matrix:\n",
      " [[89723 33334 21360 10888]\n",
      " [57127 42210 34134 21200]\n",
      " [33222 34740 43034 43105]\n",
      " [12380 16007 29764 99546]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lightgbm.callback import early_stopping, log_evaluation\n",
    "import time\n",
    "import math\n",
    "\n",
    "# IMPORTANT: reset indexes to avoid KeyError\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = pd.Series(y_train).reset_index(drop=True)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RND)\n",
    "fold = 0\n",
    "accs, f1s = [], []\n",
    "cm_sum = None\n",
    "models = []\n",
    "\n",
    "for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "    fold += 1\n",
    "    \n",
    "    # FIX: use iloc to index properly\n",
    "    X_tr = X_train.iloc[train_idx]\n",
    "    y_tr = y_train.iloc[train_idx]\n",
    "    X_val = X_train.iloc[val_idx]\n",
    "    y_val = y_train.iloc[val_idx]\n",
    "\n",
    "    model = lgb.LGBMClassifier(\n",
    "        objective=\"multiclass\",\n",
    "        num_class=len(np.unique(y_train)),\n",
    "        boosting_type=\"gbdt\",\n",
    "        learning_rate=0.03,\n",
    "        n_estimators=3000,\n",
    "        num_leaves=64,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=0.1,\n",
    "        random_state=RND,\n",
    "        verbose=-1\n",
    "    )\n",
    "\n",
    "    print(f\"\\n--- Fold {fold} training ---\")\n",
    "    t0 = time.time()\n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric=\"multi_logloss\",\n",
    "        callbacks=[log_evaluation(period=100), early_stopping(stopping_rounds=80)]\n",
    "    )\n",
    "    t1 = time.time()\n",
    "    print(f\"Fold {fold} trained in {t1-t0:.1f}s; best_iter={model.best_iteration_}\")\n",
    "\n",
    "    y_val_pred = model.predict(X_val, num_iteration=model.best_iteration_)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "    accs.append(acc); f1s.append(f1)\n",
    "    print(f\"Fold {fold} Acc: {acc:.4f} Macro-F1: {f1:.4f}\")\n",
    "\n",
    "    cm = confusion_matrix(y_val, y_val_pred)\n",
    "    cm_sum = cm if cm_sum is None else cm_sum + cm\n",
    "\n",
    "    models.append(model)\n",
    "\n",
    "print(\"\\n=== CV Results ===\")\n",
    "print(\"Accuracy per fold:\", accs)\n",
    "print(\"Macro-F1 per fold:\", f1s)\n",
    "print(\"Mean Acc: %.4f (std %.4f)\" % (np.mean(accs), np.std(accs)))\n",
    "print(\"Mean Macro-F1: %.4f (std %.4f)\" % (np.mean(f1s), np.std(f1s)))\n",
    "print(\"Aggregated confusion matrix:\\n\", cm_sum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb96d38b",
   "metadata": {},
   "source": [
    "\n",
    "### 5. Entrenamiento final y evaluación sobre test\n",
    "- Objetivo: entrenar un modelo final sobre todo el conjunto de entrenamiento (X_train completo) y evaluar su rendimiento en X_test.\n",
    "- Proceso:\n",
    "    - Se crea otro `LGBMClassifier` con la misma configuración.\n",
    "    - Se llama a `fit` usando `eval_set=[(X_test,y_test)]` y los mismos callbacks (log_evaluation + early_stopping) para controlar iteraciones y ver rendimiento en el test durante el entrenamiento.\n",
    "    - Se recupera `final_model.best_iteration_` y se predice con `predict(..., num_iteration=best_iteration_)`.\n",
    "- Salidas impresas:\n",
    "    - Best iteration, accuracy y macro-F1 sobre X_test.\n",
    "    - `classification_report` con precision/recall/f1 por clase y la `confusion_matrix`.\n",
    "- Nota práctica: este modelo final es el que luego se usa para predecir sobre datos nuevos (test set de producción)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "822a301a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's multi_logloss: 1.2206\n",
      "[200]\tvalid_0's multi_logloss: 1.20789\n",
      "[300]\tvalid_0's multi_logloss: 1.20421\n",
      "[400]\tvalid_0's multi_logloss: 1.2034\n",
      "[500]\tvalid_0's multi_logloss: 1.2027\n",
      "[600]\tvalid_0's multi_logloss: 1.20231\n",
      "[700]\tvalid_0's multi_logloss: 1.20215\n",
      "[800]\tvalid_0's multi_logloss: 1.20195\n",
      "Early stopping, best iteration is:\n",
      "[819]\tvalid_0's multi_logloss: 1.20193\n",
      "Final best_iter: 819\n",
      "Test accuracy: 0.43216524092810515\n",
      "Test macro-F1: 0.42269458837501206\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4401    0.6315    0.5187     17256\n",
      "           1     0.3199    0.2821    0.2998     17186\n",
      "           2     0.3361    0.2630    0.2951     17123\n",
      "           3     0.6093    0.5483    0.5772     17522\n",
      "\n",
      "    accuracy                         0.4322     69087\n",
      "   macro avg     0.4263    0.4312    0.4227     69087\n",
      "weighted avg     0.4273    0.4322    0.4237     69087\n",
      "\n",
      "Confusion matrix:\n",
      " [[10898  3656  1870   832]\n",
      " [ 7463  4848  3223  1652]\n",
      " [ 4581  4361  4503  3678]\n",
      " [ 1823  2288  3803  9608]]\n"
     ]
    }
   ],
   "source": [
    "# Cell 8 — train final on X_train (all) and evaluate on X_test\n",
    "final_model = lgb.LGBMClassifier(\n",
    "    objective=\"multiclass\",\n",
    "    num_class=len(np.unique(y_numeric)),\n",
    "    boosting_type=\"gbdt\",\n",
    "    learning_rate=0.03,\n",
    "    n_estimators=3000,\n",
    "    num_leaves=64,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1,\n",
    "    random_state=RND,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "final_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_metric=\"multi_logloss\",\n",
    "    callbacks=[log_evaluation(period=100), early_stopping(stopping_rounds=80)]\n",
    ")\n",
    "\n",
    "print(\"Final best_iter:\", final_model.best_iteration_)\n",
    "y_test_pred = final_model.predict(X_test, num_iteration=final_model.best_iteration_)\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Test macro-F1:\", f1_score(y_test, y_test_pred, average='macro'))\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_test_pred, digits=4))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105d50f9",
   "metadata": {},
   "source": [
    "### 6. Interpretacion de los resultados\n",
    "\n",
    "- Clase 0 → mucho recall (0.63): “casos claramente malos”\n",
    "- Clase 3 → buen recall (0.55): “casos claramente buenos”\n",
    "- Clase 1 y 2 → casi aleatorias porque están “entre medios”\n",
    "\n",
    "Esto ocurre porque el espacio de features no tiene fronteras claras para separar las clases intermedias.\n",
    "El modelo NO tiene información suficiente para distinguir finamente esos grupos.\n",
    "Si las variables no contienen información predictiva\n",
    "O el fenómeno es inherentemente difuso\n",
    "O el problema es ordinal, pero se trata como “clases duras”\n",
    "\n",
    "Aun y con esto, la mejora respecto a los demas en kaggle submission es sustancial y esto lo vuelve candidato a seleccion por motivos de tiempo y trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c17cdcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 0, 1, 0, 2, 0, 1, 1, 1, 1]), numpy.ndarray)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred[:10] , type(y_test_pred) # mostrar primeras 10 predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314a0d3e",
   "metadata": {},
   "source": [
    "### 7. Creacion del Submission a Kaggle\n",
    "\n",
    "- Definición de utilidad\n",
    "    - numeric_to_label: función que convierte arreglos numéricos {0,1,2,3} a etiquetas de texto (\"bajo\", \"medio-bajo\", \"medio-alto\", \"alto\") usando `np.vectorize`.\n",
    "\n",
    "- Carga y vista rápida del set de test\n",
    "    - test_df: se carga `data/test.csv` y se inspecciona con `head()`.\n",
    "\n",
    "- Preprocesado y extracción de IDs\n",
    "    - X_test_new, ids_test_new = preprocess_new(test_df): aplica el mismo preprocesado usado en entrenamiento (mapa de ordinales/binning, imputaciones, escalado, y extracción de la columna `ID`). `ids_test_new` se guarda para la salida final.\n",
    "\n",
    "- Feature engineering sobre los datos nuevos\n",
    "    - X_test_new_fe = feature_engineer(X_test_new, ...): genera nuevas variables (flags de missing, bins, interacciones, frequency encodings, clustering, label-encoding, etc.). Nota: aquí no se pasa `y`, por lo que no se hace target-mean OOF; además el KMeans y LabelEncoder se ajustan de nuevo sobre el test (puede producir diferencias frente a lo usado en entrenamiento si no se reutilizan los mapas/ modelos guardados).\n",
    "\n",
    "- Limpieza puntual\n",
    "    - Se elimina `prg_estrato`, probablemente porque no coincide con las columnas usadas por el modelo final.\n",
    "\n",
    "- Predicción y comprobaciones\n",
    "    - y_test_proba = final_model.predict(...): se obtienen las predicciones numéricas del modelo final. Atención: el nombre `y_test_proba` es engañoso — aquí hay etiquetas predichas, no probabilidades.\n",
    "    - Se muestran ejemplos y se verifican shapes (celdas 31, 33).\n",
    "\n",
    "- Conversión a etiquetas textuales y creación del CSV de submission\n",
    "    - rendimiento_global_pred = numeric_to_label(y_test_proba): mapea los números a las etiquetas finales.\n",
    "    - kaggle_submission: DataFrame con `ID` y `RENDIMIENTO_GLOBAL`.\n",
    "    - kaggle_submission.to_csv(...): escribe `kaggle_submission_2.csv` listo para subir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecfc57a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_to_label(arr):\n",
    "    mapping = {\n",
    "        0: \"bajo\",\n",
    "        1: \"medio-bajo\",\n",
    "        2: \"medio-alto\",\n",
    "        3: \"alto\"\n",
    "    }\n",
    "    \n",
    "    # Vectorizamos el diccionario para aplicarlo a cada elemento\n",
    "    vectorized_map = np.vectorize(lambda x: mapping.get(x, \"valor-desconocido\"))\n",
    "    return vectorized_map(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f020cb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68f87854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PERIODO_ACADEMICO</th>\n",
       "      <th>E_PRGM_ACADEMICO</th>\n",
       "      <th>E_PRGM_DEPARTAMENTO</th>\n",
       "      <th>E_VALORMATRICULAUNIVERSIDAD</th>\n",
       "      <th>E_HORASSEMANATRABAJA</th>\n",
       "      <th>F_ESTRATOVIVIENDA</th>\n",
       "      <th>F_TIENEINTERNET</th>\n",
       "      <th>F_EDUCACIONPADRE</th>\n",
       "      <th>F_TIENELAVADORA</th>\n",
       "      <th>F_TIENEAUTOMOVIL</th>\n",
       "      <th>E_PRIVADO_LIBERTAD</th>\n",
       "      <th>E_PAGOMATRICULAPROPIO</th>\n",
       "      <th>F_TIENECOMPUTADOR</th>\n",
       "      <th>F_TIENEINTERNET.1</th>\n",
       "      <th>F_EDUCACIONMADRE</th>\n",
       "      <th>INDICADOR_1</th>\n",
       "      <th>INDICADOR_2</th>\n",
       "      <th>INDICADOR_3</th>\n",
       "      <th>INDICADOR_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>550236</td>\n",
       "      <td>20183</td>\n",
       "      <td>TRABAJO SOCIAL</td>\n",
       "      <td>BOLIVAR</td>\n",
       "      <td>Menos de 500 mil</td>\n",
       "      <td>Menos de 10 horas</td>\n",
       "      <td>Estrato 3</td>\n",
       "      <td>Si</td>\n",
       "      <td>Técnica o tecnológica completa</td>\n",
       "      <td>Si</td>\n",
       "      <td>No</td>\n",
       "      <td>N</td>\n",
       "      <td>Si</td>\n",
       "      <td>Si</td>\n",
       "      <td>Si</td>\n",
       "      <td>Primaria completa</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98545</td>\n",
       "      <td>20203</td>\n",
       "      <td>ADMINISTRACION COMERCIAL Y DE MERCADEO</td>\n",
       "      <td>ANTIOQUIA</td>\n",
       "      <td>Entre 2.5 millones y menos de 4 millones</td>\n",
       "      <td>Entre 21 y 30 horas</td>\n",
       "      <td>Estrato 2</td>\n",
       "      <td>Si</td>\n",
       "      <td>Secundaria (Bachillerato) completa</td>\n",
       "      <td>Si</td>\n",
       "      <td>No</td>\n",
       "      <td>N</td>\n",
       "      <td>No</td>\n",
       "      <td>Si</td>\n",
       "      <td>Si</td>\n",
       "      <td>Técnica o tecnológica completa</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>499179</td>\n",
       "      <td>20212</td>\n",
       "      <td>INGENIERIA MECATRONICA</td>\n",
       "      <td>BOGOTÁ</td>\n",
       "      <td>Entre 1 millón y menos de 2.5 millones</td>\n",
       "      <td>0</td>\n",
       "      <td>Estrato 3</td>\n",
       "      <td>Si</td>\n",
       "      <td>Secundaria (Bachillerato) incompleta</td>\n",
       "      <td>Si</td>\n",
       "      <td>No</td>\n",
       "      <td>N</td>\n",
       "      <td>No</td>\n",
       "      <td>Si</td>\n",
       "      <td>Si</td>\n",
       "      <td>Secundaria (Bachillerato) completa</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>782980</td>\n",
       "      <td>20195</td>\n",
       "      <td>CONTADURIA PUBLICA</td>\n",
       "      <td>SUCRE</td>\n",
       "      <td>Entre 1 millón y menos de 2.5 millones</td>\n",
       "      <td>Entre 21 y 30 horas</td>\n",
       "      <td>Estrato 1</td>\n",
       "      <td>No</td>\n",
       "      <td>Primaria incompleta</td>\n",
       "      <td>Si</td>\n",
       "      <td>No</td>\n",
       "      <td>N</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Primaria incompleta</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>785185</td>\n",
       "      <td>20212</td>\n",
       "      <td>ADMINISTRACION DE EMPRESAS</td>\n",
       "      <td>ATLANTICO</td>\n",
       "      <td>Entre 2.5 millones y menos de 4 millones</td>\n",
       "      <td>Entre 11 y 20 horas</td>\n",
       "      <td>Estrato 2</td>\n",
       "      <td>Si</td>\n",
       "      <td>Secundaria (Bachillerato) completa</td>\n",
       "      <td>Si</td>\n",
       "      <td>No</td>\n",
       "      <td>N</td>\n",
       "      <td>No</td>\n",
       "      <td>Si</td>\n",
       "      <td>Si</td>\n",
       "      <td>Secundaria (Bachillerato) completa</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  PERIODO_ACADEMICO                        E_PRGM_ACADEMICO  \\\n",
       "0  550236              20183                          TRABAJO SOCIAL   \n",
       "1   98545              20203  ADMINISTRACION COMERCIAL Y DE MERCADEO   \n",
       "2  499179              20212                  INGENIERIA MECATRONICA   \n",
       "3  782980              20195                      CONTADURIA PUBLICA   \n",
       "4  785185              20212              ADMINISTRACION DE EMPRESAS   \n",
       "\n",
       "  E_PRGM_DEPARTAMENTO               E_VALORMATRICULAUNIVERSIDAD  \\\n",
       "0             BOLIVAR                          Menos de 500 mil   \n",
       "1           ANTIOQUIA  Entre 2.5 millones y menos de 4 millones   \n",
       "2              BOGOTÁ    Entre 1 millón y menos de 2.5 millones   \n",
       "3               SUCRE    Entre 1 millón y menos de 2.5 millones   \n",
       "4           ATLANTICO  Entre 2.5 millones y menos de 4 millones   \n",
       "\n",
       "  E_HORASSEMANATRABAJA F_ESTRATOVIVIENDA F_TIENEINTERNET  \\\n",
       "0    Menos de 10 horas         Estrato 3              Si   \n",
       "1  Entre 21 y 30 horas         Estrato 2              Si   \n",
       "2                    0         Estrato 3              Si   \n",
       "3  Entre 21 y 30 horas         Estrato 1              No   \n",
       "4  Entre 11 y 20 horas         Estrato 2              Si   \n",
       "\n",
       "                       F_EDUCACIONPADRE F_TIENELAVADORA F_TIENEAUTOMOVIL  \\\n",
       "0        Técnica o tecnológica completa              Si               No   \n",
       "1    Secundaria (Bachillerato) completa              Si               No   \n",
       "2  Secundaria (Bachillerato) incompleta              Si               No   \n",
       "3                   Primaria incompleta              Si               No   \n",
       "4    Secundaria (Bachillerato) completa              Si               No   \n",
       "\n",
       "  E_PRIVADO_LIBERTAD E_PAGOMATRICULAPROPIO F_TIENECOMPUTADOR  \\\n",
       "0                  N                    Si                Si   \n",
       "1                  N                    No                Si   \n",
       "2                  N                    No                Si   \n",
       "3                  N                    No                No   \n",
       "4                  N                    No                Si   \n",
       "\n",
       "  F_TIENEINTERNET.1                    F_EDUCACIONMADRE  INDICADOR_1  \\\n",
       "0                Si                   Primaria completa        0.328   \n",
       "1                Si      Técnica o tecnológica completa        0.227   \n",
       "2                Si  Secundaria (Bachillerato) completa        0.285   \n",
       "3                No                 Primaria incompleta        0.160   \n",
       "4                Si  Secundaria (Bachillerato) completa        0.209   \n",
       "\n",
       "   INDICADOR_2  INDICADOR_3  INDICADOR_4  \n",
       "0        0.219        0.317        0.247  \n",
       "1        0.283        0.296        0.324  \n",
       "2        0.228        0.294        0.247  \n",
       "3        0.408        0.217        0.294  \n",
       "4        0.283        0.306        0.286  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "883a2db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JUANJO\\AppData\\Local\\Temp\\ipykernel_3948\\2178492099.py:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['E_PRGM_ACADEMICO_ENC'].fillna(global_mean, inplace=True)\n",
      "C:\\Users\\JUANJO\\AppData\\Local\\Temp\\ipykernel_3948\\2178492099.py:40: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['E_PRGM_DEPARTAMENTO_ENC'].fillna(global_mean, inplace=True)\n",
      "C:\\Users\\JUANJO\\AppData\\Local\\Temp\\ipykernel_3948\\2178492099.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(fill_val, inplace=True)\n",
      "C:\\Users\\JUANJO\\AppData\\Local\\Temp\\ipykernel_3948\\2178492099.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(fill_val, inplace=True)\n",
      "C:\\Users\\JUANJO\\AppData\\Local\\Temp\\ipykernel_3948\\2178492099.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(fill_val, inplace=True)\n",
      "C:\\Users\\JUANJO\\AppData\\Local\\Temp\\ipykernel_3948\\2178492099.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(fill_val, inplace=True)\n",
      "C:\\Users\\JUANJO\\AppData\\Local\\Temp\\ipykernel_3948\\2178492099.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(fill_val, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "X_test_new, ids_test_new = preprocess_new(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a2d1416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERIODO_ACADEMICO</th>\n",
       "      <th>E_VALORMATRICULAUNIVERSIDAD</th>\n",
       "      <th>E_HORASSEMANATRABAJA</th>\n",
       "      <th>F_ESTRATOVIVIENDA</th>\n",
       "      <th>F_TIENEINTERNET</th>\n",
       "      <th>F_EDUCACIONPADRE</th>\n",
       "      <th>F_TIENELAVADORA</th>\n",
       "      <th>F_TIENEAUTOMOVIL</th>\n",
       "      <th>E_PAGOMATRICULAPROPIO</th>\n",
       "      <th>F_TIENECOMPUTADOR</th>\n",
       "      <th>F_EDUCACIONMADRE</th>\n",
       "      <th>INDICADOR_1</th>\n",
       "      <th>INDICADOR_2</th>\n",
       "      <th>INDICADOR_3</th>\n",
       "      <th>INDICADOR_4</th>\n",
       "      <th>E_PRGM_ACADEMICO_ENC</th>\n",
       "      <th>E_PRGM_DEPARTAMENTO_ENC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.499239</td>\n",
       "      <td>0.449692</td>\n",
       "      <td>0.990625</td>\n",
       "      <td>0.743976</td>\n",
       "      <td>0.276905</td>\n",
       "      <td>0.584647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.345510</td>\n",
       "      <td>0.581109</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>0.347838</td>\n",
       "      <td>0.831733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.433790</td>\n",
       "      <td>0.468172</td>\n",
       "      <td>0.918750</td>\n",
       "      <td>0.743976</td>\n",
       "      <td>0.726086</td>\n",
       "      <td>0.761121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.243531</td>\n",
       "      <td>0.837782</td>\n",
       "      <td>0.678125</td>\n",
       "      <td>0.885542</td>\n",
       "      <td>0.353210</td>\n",
       "      <td>0.387345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.318113</td>\n",
       "      <td>0.581109</td>\n",
       "      <td>0.956250</td>\n",
       "      <td>0.861446</td>\n",
       "      <td>0.396928</td>\n",
       "      <td>0.695386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PERIODO_ACADEMICO  E_VALORMATRICULAUNIVERSIDAD  E_HORASSEMANATRABAJA  \\\n",
       "0           0.000000                            1                     1   \n",
       "1           0.666667                            4                     3   \n",
       "2           0.966667                            3                     0   \n",
       "3           0.400000                            3                     3   \n",
       "4           0.966667                            4                     2   \n",
       "\n",
       "   F_ESTRATOVIVIENDA  F_TIENEINTERNET  F_EDUCACIONPADRE  F_TIENELAVADORA  \\\n",
       "0                  3                0                 6                0   \n",
       "1                  2                0                 4                0   \n",
       "2                  3                0                 3                0   \n",
       "3                  1                1                 1                0   \n",
       "4                  2                0                 4                0   \n",
       "\n",
       "   F_TIENEAUTOMOVIL  E_PAGOMATRICULAPROPIO  F_TIENECOMPUTADOR  \\\n",
       "0                 1                      1                  0   \n",
       "1                 1                      0                  0   \n",
       "2                 1                      0                  0   \n",
       "3                 1                      0                  1   \n",
       "4                 1                      0                  0   \n",
       "\n",
       "   F_EDUCACIONMADRE  INDICADOR_1  INDICADOR_2  INDICADOR_3  INDICADOR_4  \\\n",
       "0                 2     0.499239     0.449692     0.990625     0.743976   \n",
       "1                 6     0.345510     0.581109     0.925000     0.975904   \n",
       "2                 4     0.433790     0.468172     0.918750     0.743976   \n",
       "3                 1     0.243531     0.837782     0.678125     0.885542   \n",
       "4                 4     0.318113     0.581109     0.956250     0.861446   \n",
       "\n",
       "   E_PRGM_ACADEMICO_ENC  E_PRGM_DEPARTAMENTO_ENC  \n",
       "0              0.276905                 0.584647  \n",
       "1              0.347838                 0.831733  \n",
       "2              0.726086                 0.761121  \n",
       "3              0.353210                 0.387345  \n",
       "4              0.396928                 0.695386  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7ae5f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new_fe, _ = feature_engineer(\n",
    "    X_test_new,\n",
    "    do_kmeans=True,\n",
    "    kmeans_k=8,\n",
    "    save_maps_path=\"data/fe_maps.pkl\"\n",
    ")             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5cf2f42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERIODO_ACADEMICO</th>\n",
       "      <th>E_VALORMATRICULAUNIVERSIDAD</th>\n",
       "      <th>E_HORASSEMANATRABAJA</th>\n",
       "      <th>F_ESTRATOVIVIENDA</th>\n",
       "      <th>F_TIENEINTERNET</th>\n",
       "      <th>F_EDUCACIONPADRE</th>\n",
       "      <th>F_TIENELAVADORA</th>\n",
       "      <th>F_TIENEAUTOMOVIL</th>\n",
       "      <th>E_PAGOMATRICULAPROPIO</th>\n",
       "      <th>F_TIENECOMPUTADOR</th>\n",
       "      <th>...</th>\n",
       "      <th>prg_INDICADOR_3_mean</th>\n",
       "      <th>prg_INDICADOR_3_std</th>\n",
       "      <th>prg_INDICADOR_3_count</th>\n",
       "      <th>prg_INDICADOR_4_mean</th>\n",
       "      <th>prg_INDICADOR_4_std</th>\n",
       "      <th>prg_INDICADOR_4_count</th>\n",
       "      <th>cluster_indic</th>\n",
       "      <th>prg_estrato</th>\n",
       "      <th>prg_estrato_freq</th>\n",
       "      <th>prg_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795567</td>\n",
       "      <td>0.196588</td>\n",
       "      <td>5286</td>\n",
       "      <td>0.826230</td>\n",
       "      <td>0.203492</td>\n",
       "      <td>5286</td>\n",
       "      <td>4</td>\n",
       "      <td>0.27690477849910805_3</td>\n",
       "      <td>1513</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832837</td>\n",
       "      <td>0.193746</td>\n",
       "      <td>195</td>\n",
       "      <td>0.749382</td>\n",
       "      <td>0.210195</td>\n",
       "      <td>195</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3478380318863289_2</td>\n",
       "      <td>53</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.837931</td>\n",
       "      <td>0.178425</td>\n",
       "      <td>964</td>\n",
       "      <td>0.791106</td>\n",
       "      <td>0.190470</td>\n",
       "      <td>964</td>\n",
       "      <td>6</td>\n",
       "      <td>0.7260863431985197_3</td>\n",
       "      <td>412</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822151</td>\n",
       "      <td>0.179429</td>\n",
       "      <td>16861</td>\n",
       "      <td>0.828942</td>\n",
       "      <td>0.184349</td>\n",
       "      <td>16861</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3532100667724726_1</td>\n",
       "      <td>3665</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819981</td>\n",
       "      <td>0.182322</td>\n",
       "      <td>22298</td>\n",
       "      <td>0.783877</td>\n",
       "      <td>0.207804</td>\n",
       "      <td>22298</td>\n",
       "      <td>1</td>\n",
       "      <td>0.39692784238156564_2</td>\n",
       "      <td>7654</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PERIODO_ACADEMICO  E_VALORMATRICULAUNIVERSIDAD  E_HORASSEMANATRABAJA  \\\n",
       "0           0.000000                            1                     1   \n",
       "1           0.666667                            4                     3   \n",
       "2           0.966667                            3                     0   \n",
       "3           0.400000                            3                     3   \n",
       "4           0.966667                            4                     2   \n",
       "\n",
       "   F_ESTRATOVIVIENDA  F_TIENEINTERNET  F_EDUCACIONPADRE  F_TIENELAVADORA  \\\n",
       "0                  3                0                 6                0   \n",
       "1                  2                0                 4                0   \n",
       "2                  3                0                 3                0   \n",
       "3                  1                1                 1                0   \n",
       "4                  2                0                 4                0   \n",
       "\n",
       "   F_TIENEAUTOMOVIL  E_PAGOMATRICULAPROPIO  F_TIENECOMPUTADOR  ...  \\\n",
       "0                 1                      1                  0  ...   \n",
       "1                 1                      0                  0  ...   \n",
       "2                 1                      0                  0  ...   \n",
       "3                 1                      0                  1  ...   \n",
       "4                 1                      0                  0  ...   \n",
       "\n",
       "   prg_INDICADOR_3_mean  prg_INDICADOR_3_std  prg_INDICADOR_3_count  \\\n",
       "0              0.795567             0.196588                   5286   \n",
       "1              0.832837             0.193746                    195   \n",
       "2              0.837931             0.178425                    964   \n",
       "3              0.822151             0.179429                  16861   \n",
       "4              0.819981             0.182322                  22298   \n",
       "\n",
       "   prg_INDICADOR_4_mean  prg_INDICADOR_4_std  prg_INDICADOR_4_count  \\\n",
       "0              0.826230             0.203492                   5286   \n",
       "1              0.749382             0.210195                    195   \n",
       "2              0.791106             0.190470                    964   \n",
       "3              0.828942             0.184349                  16861   \n",
       "4              0.783877             0.207804                  22298   \n",
       "\n",
       "   cluster_indic            prg_estrato  prg_estrato_freq  prg_idx  \n",
       "0              4  0.27690477849910805_3              1513       95  \n",
       "1              5   0.3478380318863289_2                53      169  \n",
       "2              6   0.7260863431985197_3               412      716  \n",
       "3              3   0.3532100667724726_1              3665      176  \n",
       "4              1  0.39692784238156564_2              7654      238  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_new_fe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f5226ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new_fe.drop(columns=[\"prg_estrato\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dc307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_proba = final_model.predict(X_test_new_fe, num_iteration=final_model.best_iteration_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8a5e1808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1, 1, 3, 1, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_proba[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "90d3aa4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    550236\n",
       "1     98545\n",
       "2    499179\n",
       "3    782980\n",
       "4    785185\n",
       "Name: ID, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_test_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4780226b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((296786,), (296786,))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_test_new.shape, y_test_proba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "17906572",
   "metadata": {},
   "outputs": [],
   "source": [
    "rendimiento_global_pred = numeric_to_label(y_test_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "05e331e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_submission = pd.DataFrame({\n",
    "    \"ID\": ids_test_new,\n",
    "    \"RENDIMIENTO_GLOBAL\": rendimiento_global_pred\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "814f2d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>RENDIMIENTO_GLOBAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>550236</td>\n",
       "      <td>medio-bajo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98545</td>\n",
       "      <td>medio-bajo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>499179</td>\n",
       "      <td>medio-bajo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>782980</td>\n",
       "      <td>bajo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>785185</td>\n",
       "      <td>medio-bajo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID RENDIMIENTO_GLOBAL\n",
       "0  550236         medio-bajo\n",
       "1   98545         medio-bajo\n",
       "2  499179         medio-bajo\n",
       "3  782980               bajo\n",
       "4  785185         medio-bajo"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "26ce7002",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_submission.to_csv('kaggle_submission_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da7f13b",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "\n",
    "- El pipeline (preprocesado + feature engineering + LightGBM) aporta buena separación para clases extremas (bajo/alto) pero falla en distinguir las clases intermedias (medio-bajo/medio-alto).  \n",
    "- Métricas CV y test muestran estabilidad en extremos pero baja discriminación en el centro, indicando información insuficiente o ruido en las features para ese nivel de granularidad.  \n",
    "- **Recomendaciones prácticas:** considerar modelos/objetivos ordinales, recopilar features más informativas, y reutilizar mapas/modelos de FE (encoders, KMeans) al predecir para mejorar consistencia en producción."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
