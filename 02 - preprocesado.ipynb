{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c8d5a78",
   "metadata": {},
   "source": [
    "# Pre procesamiento de Datos\n",
    "\n",
    "El pre procesamiento de los dato es un paso clave en el Machine/Deep learning, pues en la mayoria de los casos los datasets de entrenamiento no vienen listos o formateados lo suficiente como para ser usados directamente como entrenamiento, por lo mismo se realiza este proceso.\n",
    "\n",
    "En este notebook se desarrolla el pre procesamiento de los datos de entrenamiento para el proyecto final\n",
    "\n",
    "En este notebook se han realizado diversas transformaciones y preprocesamientos sobre los datos, tales como la imputación de valores nulos, la normalización de variables, la codificación de variables categóricas y ordinales, y la preparación de los conjuntos de datos para su uso en modelos de Machine Learning. Además, se han implementado técnicas como el encoding suavizado y el one-hot encoding para el tratamiento de variables categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c547e34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ae04641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el conjunto de datos\n",
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9de7c47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PERIODO_ACADEMICO</th>\n",
       "      <th>E_PRGM_ACADEMICO</th>\n",
       "      <th>E_PRGM_DEPARTAMENTO</th>\n",
       "      <th>E_VALORMATRICULAUNIVERSIDAD</th>\n",
       "      <th>E_HORASSEMANATRABAJA</th>\n",
       "      <th>F_ESTRATOVIVIENDA</th>\n",
       "      <th>F_TIENEINTERNET</th>\n",
       "      <th>F_EDUCACIONPADRE</th>\n",
       "      <th>F_TIENELAVADORA</th>\n",
       "      <th>...</th>\n",
       "      <th>E_PRIVADO_LIBERTAD</th>\n",
       "      <th>E_PAGOMATRICULAPROPIO</th>\n",
       "      <th>F_TIENECOMPUTADOR</th>\n",
       "      <th>F_TIENEINTERNET.1</th>\n",
       "      <th>F_EDUCACIONMADRE</th>\n",
       "      <th>RENDIMIENTO_GLOBAL</th>\n",
       "      <th>INDICADOR_1</th>\n",
       "      <th>INDICADOR_2</th>\n",
       "      <th>INDICADOR_3</th>\n",
       "      <th>INDICADOR_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>904256</td>\n",
       "      <td>20212</td>\n",
       "      <td>ENFERMERIA</td>\n",
       "      <td>BOGOTÁ</td>\n",
       "      <td>Entre 5.5 millones y menos de 7 millones</td>\n",
       "      <td>Menos de 10 horas</td>\n",
       "      <td>Estrato 3</td>\n",
       "      <td>Si</td>\n",
       "      <td>Técnica o tecnológica incompleta</td>\n",
       "      <td>Si</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>No</td>\n",
       "      <td>Si</td>\n",
       "      <td>Si</td>\n",
       "      <td>Postgrado</td>\n",
       "      <td>medio-alto</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>645256</td>\n",
       "      <td>20212</td>\n",
       "      <td>DERECHO</td>\n",
       "      <td>ATLANTICO</td>\n",
       "      <td>Entre 2.5 millones y menos de 4 millones</td>\n",
       "      <td>0</td>\n",
       "      <td>Estrato 3</td>\n",
       "      <td>No</td>\n",
       "      <td>Técnica o tecnológica completa</td>\n",
       "      <td>Si</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>No</td>\n",
       "      <td>Si</td>\n",
       "      <td>No</td>\n",
       "      <td>Técnica o tecnológica incompleta</td>\n",
       "      <td>bajo</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>308367</td>\n",
       "      <td>20203</td>\n",
       "      <td>MERCADEO Y PUBLICIDAD</td>\n",
       "      <td>BOGOTÁ</td>\n",
       "      <td>Entre 2.5 millones y menos de 4 millones</td>\n",
       "      <td>Más de 30 horas</td>\n",
       "      <td>Estrato 3</td>\n",
       "      <td>Si</td>\n",
       "      <td>Secundaria (Bachillerato) completa</td>\n",
       "      <td>Si</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Si</td>\n",
       "      <td>Secundaria (Bachillerato) completa</td>\n",
       "      <td>bajo</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>470353</td>\n",
       "      <td>20195</td>\n",
       "      <td>ADMINISTRACION DE EMPRESAS</td>\n",
       "      <td>SANTANDER</td>\n",
       "      <td>Entre 4 millones y menos de 5.5 millones</td>\n",
       "      <td>0</td>\n",
       "      <td>Estrato 4</td>\n",
       "      <td>Si</td>\n",
       "      <td>No sabe</td>\n",
       "      <td>Si</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>No</td>\n",
       "      <td>Si</td>\n",
       "      <td>Si</td>\n",
       "      <td>Secundaria (Bachillerato) completa</td>\n",
       "      <td>alto</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>989032</td>\n",
       "      <td>20212</td>\n",
       "      <td>PSICOLOGIA</td>\n",
       "      <td>ANTIOQUIA</td>\n",
       "      <td>Entre 2.5 millones y menos de 4 millones</td>\n",
       "      <td>Entre 21 y 30 horas</td>\n",
       "      <td>Estrato 3</td>\n",
       "      <td>Si</td>\n",
       "      <td>Primaria completa</td>\n",
       "      <td>Si</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>No</td>\n",
       "      <td>Si</td>\n",
       "      <td>Si</td>\n",
       "      <td>Primaria completa</td>\n",
       "      <td>medio-bajo</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  PERIODO_ACADEMICO            E_PRGM_ACADEMICO E_PRGM_DEPARTAMENTO  \\\n",
       "0  904256              20212                  ENFERMERIA              BOGOTÁ   \n",
       "1  645256              20212                     DERECHO           ATLANTICO   \n",
       "2  308367              20203       MERCADEO Y PUBLICIDAD              BOGOTÁ   \n",
       "3  470353              20195  ADMINISTRACION DE EMPRESAS           SANTANDER   \n",
       "4  989032              20212                  PSICOLOGIA           ANTIOQUIA   \n",
       "\n",
       "                E_VALORMATRICULAUNIVERSIDAD E_HORASSEMANATRABAJA  \\\n",
       "0  Entre 5.5 millones y menos de 7 millones    Menos de 10 horas   \n",
       "1  Entre 2.5 millones y menos de 4 millones                    0   \n",
       "2  Entre 2.5 millones y menos de 4 millones      Más de 30 horas   \n",
       "3  Entre 4 millones y menos de 5.5 millones                    0   \n",
       "4  Entre 2.5 millones y menos de 4 millones  Entre 21 y 30 horas   \n",
       "\n",
       "  F_ESTRATOVIVIENDA F_TIENEINTERNET                    F_EDUCACIONPADRE  \\\n",
       "0         Estrato 3              Si    Técnica o tecnológica incompleta   \n",
       "1         Estrato 3              No      Técnica o tecnológica completa   \n",
       "2         Estrato 3              Si  Secundaria (Bachillerato) completa   \n",
       "3         Estrato 4              Si                             No sabe   \n",
       "4         Estrato 3              Si                   Primaria completa   \n",
       "\n",
       "  F_TIENELAVADORA  ... E_PRIVADO_LIBERTAD E_PAGOMATRICULAPROPIO  \\\n",
       "0              Si  ...                  N                    No   \n",
       "1              Si  ...                  N                    No   \n",
       "2              Si  ...                  N                    No   \n",
       "3              Si  ...                  N                    No   \n",
       "4              Si  ...                  N                    No   \n",
       "\n",
       "  F_TIENECOMPUTADOR F_TIENEINTERNET.1                    F_EDUCACIONMADRE  \\\n",
       "0                Si                Si                           Postgrado   \n",
       "1                Si                No    Técnica o tecnológica incompleta   \n",
       "2                No                Si  Secundaria (Bachillerato) completa   \n",
       "3                Si                Si  Secundaria (Bachillerato) completa   \n",
       "4                Si                Si                   Primaria completa   \n",
       "\n",
       "  RENDIMIENTO_GLOBAL INDICADOR_1  INDICADOR_2  INDICADOR_3  INDICADOR_4  \n",
       "0         medio-alto       0.322        0.208        0.310        0.267  \n",
       "1               bajo       0.311        0.215        0.292        0.264  \n",
       "2               bajo       0.297        0.214        0.305        0.264  \n",
       "3               alto       0.485        0.172        0.252        0.190  \n",
       "4         medio-bajo       0.316        0.232        0.285        0.294  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observamos las primeras filas del DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f631f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se eliminala columna 'ID' ya que no aporta información relevante para el análisis\n",
    "df.drop(columns=['ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc8a475",
   "metadata": {},
   "source": [
    "NOTA: Este analisis de Chi cuadrado deberia haberse realizado en el archivo anterior, sin embargo fue pospuesto por tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79dde076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2cd0bb",
   "metadata": {},
   "source": [
    "Las siguientes ocho celdas realizan diversas transformaciones y análisis sobre los datos. Primero, se evalúa la independencia entre las variables categóricas E_PRGM_ACADEMICO y E_PRGM_DEPARTAMENTO con respecto a RENDIMIENTO_GLOBAL, utilizando tablas de contingencia y la prueba de Chi-cuadrado para calcular el valor p y determinar si existe una relación significativa. También se calcula el número de categorías únicas en estas variables. Posteriormente, se transforma la variable `RENDIMIENTO_GLOBAL` en una representación ordinal numérica (`RENDIMIENTO_GLOBAL_NUM`) para facilitar su uso en análisis posteriores. Además, se implementa un encoding suavizado para las variables `E_PRGM_ACADEMICO` y `E_PRGM_DEPARTAMENTO`, calculando una combinación ponderada entre la media global y la media por grupo, asignando estos valores a nuevas columnas y eliminando las columnas originales.\n",
    "\n",
    "Finalmente, se crean y guardan los mapas de encoding generados para las variables categóricas, permitiendo su reutilización en futuros análisis. Estas transformaciones buscan preparar los datos para su uso en modelos de Machine Learning, asegurando que las variables categóricas sean representadas de manera adecuada y que las relaciones entre las variables sean analizadas y comprendidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f67763a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-cuadrado p-value: 0.00000000 (Significativo)\n"
     ]
    }
   ],
   "source": [
    "# Análisis de independencia entre 'E_PRGM_DEPARTAMENTO' y 'RENDIMIENTO_GLOBAL'\n",
    "cont = pd.crosstab(df[\"E_PRGM_ACADEMICO\"], df[\"RENDIMIENTO_GLOBAL\"])\n",
    "chi2, p, dof, exp = chi2_contingency(cont)\n",
    "print(f\"Chi-cuadrado p-value: {p:.8f} {'(Significativo)' if p < 0.05 else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7a3fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-cuadrado p-value: 0.00000000 (Significativo)\n"
     ]
    }
   ],
   "source": [
    "# Análisis de independencia entre 'E_PRGM_DEPARTAMENTO' y 'RENDIMIENTO_GLOBAL'\n",
    "cont = pd.crosstab(df[\"E_PRGM_DEPARTAMENTO\"], df[\"RENDIMIENTO_GLOBAL\"])\n",
    "chi2, p, dof, exp = chi2_contingency(cont)\n",
    "print(f\"Chi-cuadrado p-value: {p:.8f} {'(Significativo)' if p < 0.05 else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64a2465a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(948, 31)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numero de valores unicos de \"E_PRGM_ACADEMICO\" y de \"E_PRGM_DEPARTAMENTO\"\n",
    "df[\"E_PRGM_ACADEMICO\"].unique().size, df[\"E_PRGM_DEPARTAMENTO\"].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f97ad0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_ordinal = {\n",
    "    'bajo': 1,\n",
    "    'medio-bajo': 2,\n",
    "    'medio-alto': 3,\n",
    "    'alto': 4\n",
    "}\n",
    "df['RENDIMIENTO_GLOBAL_NUM'] = df['RENDIMIENTO_GLOBAL'].map(map_ordinal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e752a1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JUANJO\\AppData\\Local\\Temp\\ipykernel_12244\\436551978.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['E_PRGM_ACADEMICO_ENC'].fillna(global_mean, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Media global del target\n",
    "global_mean = df['RENDIMIENTO_GLOBAL_NUM'].mean()\n",
    "\n",
    "# Conteo y media por programa\n",
    "agg_prg = df.groupby(\"E_PRGM_ACADEMICO\")['RENDIMIENTO_GLOBAL_NUM'].agg(['mean', 'count'])\n",
    "agg_prg.columns = ['mean_target', 'count']\n",
    "\n",
    "# Parámetro de suavizado (ajústalo según la dispersión de tus datos)\n",
    "k = 20  \n",
    "\n",
    "# Fórmula del smoothing:\n",
    "# encoding = (mean_target * count + global_mean * k) / (count + k)\n",
    "agg_prg['encoded'] = (agg_prg['mean_target'] * agg_prg['count'] + global_mean * k) / (agg_prg['count'] + k)\n",
    "\n",
    "# --- 3️⃣ Asignar el encoding al dataframe original ---\n",
    "df['E_PRGM_ACADEMICO_ENC'] = df['E_PRGM_ACADEMICO'].map(agg_prg['encoded'])\n",
    "\n",
    "# --- 4️⃣ Rellenar posibles valores faltantes con la media global ---\n",
    "df['E_PRGM_ACADEMICO_ENC'].fillna(global_mean, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5243fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['E_PRGM_ACADEMICO'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d88953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JUANJO\\AppData\\Local\\Temp\\ipykernel_12244\\2465231645.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['E_PRGM_DEPARTAMENTO_ENC'].fillna(global_mean, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Media global del target\n",
    "global_mean = df['RENDIMIENTO_GLOBAL_NUM'].mean()\n",
    "\n",
    "# Conteo y media por departamento\n",
    "agg_dep = df.groupby(\"E_PRGM_DEPARTAMENTO\")['RENDIMIENTO_GLOBAL_NUM'].agg(['mean', 'count'])\n",
    "agg_dep.columns = ['mean_target', 'count']\n",
    "\n",
    "# Parámetro de suavizado (ajústalo según la dispersión de tus datos)\n",
    "k = 20  \n",
    "\n",
    "# Fórmula del smoothing:\n",
    "# encoding = (mean_target * count + global_mean * k) / (count + k)\n",
    "agg_dep['encoded'] = (agg_dep['mean_target'] * agg_dep['count'] + global_mean * k) / (agg_dep['count'] + k)\n",
    "\n",
    "# --- 3️⃣ Asignar el encoding al dataframe original ---\n",
    "df['E_PRGM_DEPARTAMENTO_ENC'] = df['E_PRGM_DEPARTAMENTO'].map(agg_dep['encoded'])\n",
    "\n",
    "# --- 4️⃣ Rellenar posibles valores faltantes con la media global ---\n",
    "df['E_PRGM_DEPARTAMENTO_ENC'].fillna(global_mean, inplace=True)\n",
    "df.drop(columns=['E_PRGM_DEPARTAMENTO'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b58522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalizamos creando los mapas de encoding para futuras referencias\n",
    "encoding_map_prg = agg_prg['encoded'].to_dict()\n",
    "encoding_map_dep = agg_dep['encoded'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e02119",
   "metadata": {},
   "source": [
    "\n",
    "### Codificación de variables binarias\n",
    "\n",
    "En esta celda, se identifican y transforman las columnas binarias del DataFrame `df`. Una columna binaria es aquella que tiene exactamente dos valores únicos (excluyendo valores nulos). El objetivo es convertir estas columnas en valores numéricos (0 y 1) para facilitar su uso en modelos de Machine Learning.\n",
    "\n",
    "1. **Identificación de columnas binarias**: \n",
    "    - Se recorre cada columna del DataFrame `df` y se cuenta el número de valores únicos, excluyendo los valores nulos.\n",
    "    - Si una columna tiene exactamente dos valores únicos, se considera binaria.\n",
    "\n",
    "2. **Transformación de columnas binarias**:\n",
    "    - Si la columna contiene valores booleanos (`True` y `False`), se convierten directamente a 1 y 0, respectivamente.\n",
    "    - Para columnas no booleanas, se asigna 0 al primer valor único encontrado y 1 al segundo valor único.\n",
    "\n",
    "3. **Mantenimiento de valores nulos**:\n",
    "    - Las columnas transformadas se convierten al tipo `Int64`, que permite preservar valores nulos (`NaN`).\n",
    "\n",
    "4. **Almacenamiento de mapeos**:\n",
    "    - Se guarda un diccionario `binary_maps` que contiene los mapeos utilizados para cada columna binaria. Esto permite rastrear cómo se realizó la transformación.\n",
    "\n",
    "5. **Resumen de la transformación**:\n",
    "    - Se imprime el número total de columnas binarias transformadas y los mapeos utilizados para cada una.\n",
    "\n",
    "Esta transformación es útil para estandarizar las variables binarias y prepararlas para su uso en algoritmos que requieren datos numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84980437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas binarias convertidas: 7\n",
      " - F_TIENEINTERNET: {'Si': 0, 'No': 1}\n",
      " - F_TIENELAVADORA: {'Si': 0, 'No': 1}\n",
      " - F_TIENEAUTOMOVIL: {'Si': 0, 'No': 1}\n",
      " - E_PRIVADO_LIBERTAD: {'N': 0, 'S': 1}\n",
      " - E_PAGOMATRICULAPROPIO: {'No': 0, 'Si': 1}\n",
      " - F_TIENECOMPUTADOR: {'Si': 0, 'No': 1}\n",
      " - F_TIENEINTERNET.1: {'Si': 0, 'No': 1}\n"
     ]
    }
   ],
   "source": [
    "from pandas.api.types import is_bool_dtype\n",
    "\n",
    "binary_maps = {}  # guardará mapping por columna -> {valor_original: 0/1}\n",
    "\n",
    "for col in df.columns:\n",
    "    # contar únicos excluyendo NaN\n",
    "    n_uniques = df[col].dropna().nunique()\n",
    "    if n_uniques == 2:\n",
    "        # valores en orden de aparición (determinista según el dataframe)\n",
    "        uniques = list(pd.Series(df[col].dropna().unique()))\n",
    "        \n",
    "        # caso booleano explícito: True->1, False->0\n",
    "        if is_bool_dtype(df[col]) or set(map(type, uniques)) == {bool}:\n",
    "            df[col] = df[col].astype('Int64')  # True->1, False->0, NaN preservado\n",
    "            binary_maps[col] = {True: 1, False: 0}\n",
    "        else:\n",
    "            # crear mapping: primer valor -> 0, segundo valor -> 1\n",
    "            mapping = {uniques[0]: 0, uniques[1]: 1}\n",
    "            # mapear dejando NaN intactos y usar Int64 para permitir NA\n",
    "            df[col] = df[col].map(mapping).astype('Int64')\n",
    "            binary_maps[col] = mapping\n",
    "\n",
    "# Mostrar resumen de columnas convertidas y sus mapeos\n",
    "print(f\"Columnas binarias convertidas: {len(binary_maps)}\")\n",
    "for c, m in binary_maps.items():\n",
    "    print(f\" - {c}: {m}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8864f992",
   "metadata": {},
   "source": [
    "Se eliminan las siguientes celdas:\n",
    "\n",
    "1. `E_PRIVADO_LIBERTAD` demostró no ser significativa en el archivo exploracion y analisis\n",
    "2. `F_TIENEINTERNET.1` está repetida, pues está en `F_TIENEINTERNET`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d17ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['E_PRIVADO_LIBERTAD', 'F_TIENEINTERNET.1'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb6f2b1",
   "metadata": {},
   "source": [
    "\n",
    "### Explicación de las celdas 20 a 30\n",
    "\n",
    "En las celdas 20 a 30 se realizan transformaciones y codificaciones sobre diversas variables categóricas y ordinales del DataFrame `df`. Estas transformaciones tienen como objetivo preparar los datos para su uso en modelos de Machine Learning, asegurando que las variables sean representadas de manera adecuada y que se mantenga la integridad de los datos.\n",
    "\n",
    "Primero, se exploran las variables `E_VALORMATRICULAUNIVERSIDAD`, `E_HORASSEMANATRABAJA`, y `F_EDUCACIONPADRE`, identificando sus valores únicos y mapeándolos a valores numéricos ordinales mediante diccionarios de mapeo. Posteriormente, se aplica el mismo proceso a las variables `F_EDUCACIONMADRE` y `F_ESTRATOVIVIENDA`, utilizando el mismo diccionario de mapeo para las variables relacionadas con la educación. Finalmente, se eliminan columnas redundantes o innecesarias, como `F_EDUCACIONPADRE_ORD`, y se realiza una última transformación sobre la variable `F_ESTRATOVIVIENDA`, asignando valores ordinales y preservando valores nulos (`NA`) cuando sea necesario. Estas transformaciones aseguran que las variables categóricas y ordinales sean representadas de manera consistente y numérica, facilitando su uso en modelos predictivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afb46df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Entre 5.5 millones y menos de 7 millones',\n",
       "       'Entre 2.5 millones y menos de 4 millones',\n",
       "       'Entre 4 millones y menos de 5.5 millones', 'Más de 7 millones',\n",
       "       'Entre 1 millón y menos de 2.5 millones',\n",
       "       'Entre 500 mil y menos de 1 millón', 'Menos de 500 mil',\n",
       "       'No pagó matrícula', nan], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"E_VALORMATRICULAUNIVERSIDAD\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eac39b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mapping_matricula = {\n",
    "    'No pagó matrícula': 0,\n",
    "    'Menos de 500 mil': 1,\n",
    "    'Entre 500 mil y menos de 1 millón': 2,\n",
    "    'Entre 1 millón y menos de 2.5 millones': 3,\n",
    "    'Entre 2.5 millones y menos de 4 millones': 4,\n",
    "    'Entre 4 millones y menos de 5.5 millones': 5,\n",
    "    'Entre 5.5 millones y menos de 7 millones': 6,\n",
    "    'Más de 7 millones': 7\n",
    "}\n",
    "\n",
    "# nueva columna ordinal (Int64 para preservar NA)\n",
    "df['E_VALORMATRICULAUNIVERSIDAD'] = df['E_VALORMATRICULAUNIVERSIDAD'].map(mapping_matricula).astype('Int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7784af7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Menos de 10 horas', '0', 'Más de 30 horas', 'Entre 21 y 30 horas',\n",
       "       'Entre 11 y 20 horas', nan], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"E_HORASSEMANATRABAJA\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fdc6642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_horas = {\n",
    "    '0': 0,\n",
    "    'Menos de 10 horas': 1,\n",
    "    'Entre 11 y 20 horas': 2,\n",
    "    'Entre 21 y 30 horas': 3,\n",
    "    'Más de 30 horas': 4\n",
    "}\n",
    "\n",
    "df['E_HORASSEMANATRABAJA'] = df['E_HORASSEMANATRABAJA'].map(mapping_horas).astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "67aee389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Técnica o tecnológica incompleta',\n",
       "       'Técnica o tecnológica completa',\n",
       "       'Secundaria (Bachillerato) completa', 'No sabe',\n",
       "       'Primaria completa', 'Educación profesional completa',\n",
       "       'Educación profesional incompleta', 'Primaria incompleta',\n",
       "       'Postgrado', nan, 'Secundaria (Bachillerato) incompleta',\n",
       "       'Ninguno', 'No Aplica'], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"F_EDUCACIONPADRE\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f75d2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_educacion = {\n",
    "    'Ninguno': 0,\n",
    "    'Primaria incompleta': 1,\n",
    "    'Primaria completa': 2,\n",
    "    'Secundaria (Bachillerato) incompleta': 3,\n",
    "    'Secundaria (Bachillerato) completa': 4,\n",
    "    'Técnica o tecnológica incompleta': 5,\n",
    "    'Técnica o tecnológica completa': 6,\n",
    "    'Educación profesional incompleta': 7,\n",
    "    'Educación profesional completa': 8,\n",
    "    'Postgrado': 9,\n",
    "    # Estos se dejan como NA (no interpretables ordinalmente)\n",
    "    'No sabe': pd.NA,\n",
    "    'No Aplica': pd.NA\n",
    "}\n",
    "\n",
    "# 1) Columna ordinal numérica (Int64 para preservar NA)\n",
    "df['F_EDUCACIONPADRE'] = df['F_EDUCACIONPADRE'].map(mapping_educacion).astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c95d495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['F_EDUCACIONMADRE'] = df['F_EDUCACIONMADRE'].map(mapping_educacion).astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "543005d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['F_EDUCACIONPADRE_ORD'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f3806ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Estrato 3', 'Estrato 4', 'Estrato 5', 'Estrato 2', 'Estrato 1',\n",
       "       nan, 'Estrato 6', 'Sin Estrato'], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"F_ESTRATOVIVIENDA\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9a5b1b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_estrato = {\n",
    "    'Estrato 1': 1,\n",
    "    'Estrato 2': 2,\n",
    "    'Estrato 3': 3,\n",
    "    'Estrato 4': 4,\n",
    "    'Estrato 5': 5,\n",
    "    'Estrato 6': 6,\n",
    "    \"Sin estrato\": pd.NA\n",
    "}\n",
    "\n",
    "# 1) Columna ordinal numérica (Int64 para preservar NA)\n",
    "df['F_ESTRATOVIVIENDA'] = df['F_ESTRATOVIVIENDA'].map(mapping_estrato).astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eb3b79b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERIODO_ACADEMICO</th>\n",
       "      <th>E_VALORMATRICULAUNIVERSIDAD</th>\n",
       "      <th>E_HORASSEMANATRABAJA</th>\n",
       "      <th>F_ESTRATOVIVIENDA</th>\n",
       "      <th>F_TIENEINTERNET</th>\n",
       "      <th>F_EDUCACIONPADRE</th>\n",
       "      <th>F_TIENELAVADORA</th>\n",
       "      <th>F_TIENEAUTOMOVIL</th>\n",
       "      <th>E_PAGOMATRICULAPROPIO</th>\n",
       "      <th>F_TIENECOMPUTADOR</th>\n",
       "      <th>F_EDUCACIONMADRE</th>\n",
       "      <th>RENDIMIENTO_GLOBAL</th>\n",
       "      <th>INDICADOR_1</th>\n",
       "      <th>INDICADOR_2</th>\n",
       "      <th>INDICADOR_3</th>\n",
       "      <th>INDICADOR_4</th>\n",
       "      <th>RENDIMIENTO_GLOBAL_NUM</th>\n",
       "      <th>E_PRGM_ACADEMICO_ENC</th>\n",
       "      <th>E_PRGM_DEPARTAMENTO_ENC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20212</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>medio-alto</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.267</td>\n",
       "      <td>3</td>\n",
       "      <td>2.313951</td>\n",
       "      <td>2.557377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20212</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>bajo</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.264</td>\n",
       "      <td>1</td>\n",
       "      <td>2.629414</td>\n",
       "      <td>2.454803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20203</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>bajo</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.264</td>\n",
       "      <td>1</td>\n",
       "      <td>2.480084</td>\n",
       "      <td>2.557377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20195</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>alto</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.190</td>\n",
       "      <td>4</td>\n",
       "      <td>2.298893</td>\n",
       "      <td>2.734127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20212</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>medio-bajo</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.294</td>\n",
       "      <td>2</td>\n",
       "      <td>2.466328</td>\n",
       "      <td>2.667561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PERIODO_ACADEMICO  E_VALORMATRICULAUNIVERSIDAD  E_HORASSEMANATRABAJA  \\\n",
       "0              20212                            6                     1   \n",
       "1              20212                            4                     0   \n",
       "2              20203                            4                     4   \n",
       "3              20195                            5                     0   \n",
       "4              20212                            4                     3   \n",
       "\n",
       "   F_ESTRATOVIVIENDA  F_TIENEINTERNET  F_EDUCACIONPADRE  F_TIENELAVADORA  \\\n",
       "0                  3                0                 5                0   \n",
       "1                  3                1                 6                0   \n",
       "2                  3                0                 4                0   \n",
       "3                  4                0              <NA>                0   \n",
       "4                  3                0                 2                0   \n",
       "\n",
       "   F_TIENEAUTOMOVIL  E_PAGOMATRICULAPROPIO  F_TIENECOMPUTADOR  \\\n",
       "0                 0                      0                  0   \n",
       "1                 1                      0                  0   \n",
       "2                 1                      0                  1   \n",
       "3                 1                      0                  0   \n",
       "4                 0                      0                  0   \n",
       "\n",
       "   F_EDUCACIONMADRE RENDIMIENTO_GLOBAL  INDICADOR_1  INDICADOR_2  INDICADOR_3  \\\n",
       "0                 9         medio-alto        0.322        0.208        0.310   \n",
       "1                 5               bajo        0.311        0.215        0.292   \n",
       "2                 4               bajo        0.297        0.214        0.305   \n",
       "3                 4               alto        0.485        0.172        0.252   \n",
       "4                 2         medio-bajo        0.316        0.232        0.285   \n",
       "\n",
       "   INDICADOR_4  RENDIMIENTO_GLOBAL_NUM  E_PRGM_ACADEMICO_ENC  \\\n",
       "0        0.267                       3              2.313951   \n",
       "1        0.264                       1              2.629414   \n",
       "2        0.264                       1              2.480084   \n",
       "3        0.190                       4              2.298893   \n",
       "4        0.294                       2              2.466328   \n",
       "\n",
       "   E_PRGM_DEPARTAMENTO_ENC  \n",
       "0                 2.557377  \n",
       "1                 2.454803  \n",
       "2                 2.557377  \n",
       "3                 2.734127  \n",
       "4                 2.667561  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8a10308e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(692500, 19)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121fe4df",
   "metadata": {},
   "source": [
    "\n",
    "### Imputación de valores nulos y eliminación de filas\n",
    "\n",
    "En las siguientes celdas se realiza el tratamiento de valores nulos en el dataset `df` siguiendo las reglas descritas:\n",
    "\n",
    "1. **Eliminación de filas con más del 50% de valores nulos**:\n",
    "    - Se calcula el umbral de columnas nulas permitido por fila (50% del total de columnas).\n",
    "    - Si una fila tiene más valores nulos que este umbral, se elimina del dataset.\n",
    "\n",
    "2. **Imputación de valores nulos en las filas restantes**:\n",
    "    - Para variables categóricas transformadas a ordinales o binarias:\n",
    "      - Se rellenan los valores nulos con la moda (valor más frecuente) de la columna.\n",
    "    - Para variables numéricas:\n",
    "      - Se rellenan los valores nulos con la media de la columna.\n",
    "\n",
    "Este proceso asegura que el dataset quede limpio y sin valores nulos, manteniendo la integridad de los datos y preparándolos para su uso en modelos de Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "32a88049",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Normalizar placeholders de \"desconocido\" a pd.NA (ajusta la lista si tienes otros valores)\n",
    "unknown_strings = [\n",
    "    'No sabe', 'No Aplica', 'Desconocido', 'Desconocida',\n",
    "    'Unknown', 'NA', 'N/A', 'Sin dato', 'sin dato', ''\n",
    "]\n",
    "# Reemplazamos (inplace)\n",
    "df.replace(unknown_strings, pd.NA, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6055651d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas totales antes: 692500\n",
      "Filas a eliminar (>9 columnas nulas): 1639\n"
     ]
    }
   ],
   "source": [
    "# 2) Eliminar filas con más del 50% de columnas nulas\n",
    "n_cols = df.shape[1]\n",
    "threshold = 0.5 * n_cols\n",
    "\n",
    "# contar NaNs por fila (usando isna() que reconoce pd.NA y np.nan)\n",
    "null_counts = df.isna().sum(axis=1)\n",
    "rows_to_drop = df.index[null_counts > threshold]\n",
    "\n",
    "print(f\"Filas totales antes: {len(df)}\")\n",
    "print(f\"Filas a eliminar (>{int(threshold)} columnas nulas): {len(rows_to_drop)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b08c1f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas totales después de eliminar: 690861\n"
     ]
    }
   ],
   "source": [
    "# eliminar inplace\n",
    "if len(rows_to_drop) > 0:\n",
    "    df.drop(index=rows_to_drop, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    print(f\"Filas totales después de eliminar: {len(df)}\")\n",
    "else:\n",
    "    print(\"No se eliminaron filas (ninguna supera el 50% de nulos).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d891343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_categorical_dtype, is_numeric_dtype, is_integer_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "50014458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumen de imputaciones (columna: estrategia -> valor):\n",
      " - E_VALORMATRICULAUNIVERSIDAD: mean_rounded -> 4\n",
      " - E_HORASSEMANATRABAJA: mean_rounded -> 2\n",
      " - F_ESTRATOVIVIENDA: mean_rounded -> 3\n",
      " - F_TIENEINTERNET: mode -> 0\n",
      " - F_EDUCACIONPADRE: mean_rounded -> 4\n",
      " - F_TIENELAVADORA: mode -> 0\n",
      " - F_TIENEAUTOMOVIL: mode -> 1\n",
      " - E_PAGOMATRICULAPROPIO: mode -> 0\n",
      " - F_TIENECOMPUTADOR: mode -> 0\n",
      " - F_EDUCACIONMADRE: mean_rounded -> 4\n",
      "\n",
      "Comprobación rápida de nulos residuales por columna (debería ser 0 en la mayoría):\n",
      "PERIODO_ACADEMICO              0\n",
      "E_VALORMATRICULAUNIVERSIDAD    0\n",
      "E_HORASSEMANATRABAJA           0\n",
      "F_ESTRATOVIVIENDA              0\n",
      "F_TIENEINTERNET                0\n",
      "F_EDUCACIONPADRE               0\n",
      "F_TIENELAVADORA                0\n",
      "F_TIENEAUTOMOVIL               0\n",
      "E_PAGOMATRICULAPROPIO          0\n",
      "F_TIENECOMPUTADOR              0\n",
      "F_EDUCACIONMADRE               0\n",
      "RENDIMIENTO_GLOBAL             0\n",
      "INDICADOR_1                    0\n",
      "INDICADOR_2                    0\n",
      "INDICADOR_3                    0\n",
      "INDICADOR_4                    0\n",
      "RENDIMIENTO_GLOBAL_NUM         0\n",
      "E_PRGM_ACADEMICO_ENC           0\n",
      "E_PRGM_DEPARTAMENTO_ENC        0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JUANJO\\AppData\\Local\\Temp\\ipykernel_12244\\2626026109.py:18: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  is_categorical_dtype(df[col]) or\n",
      "C:\\Users\\JUANJO\\AppData\\Local\\Temp\\ipykernel_12244\\2626026109.py:78: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(impute_val, inplace=True)\n",
      "C:\\Users\\JUANJO\\AppData\\Local\\Temp\\ipykernel_12244\\2626026109.py:18: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  is_categorical_dtype(df[col]) or\n",
      "C:\\Users\\JUANJO\\AppData\\Local\\Temp\\ipykernel_12244\\2626026109.py:78: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(impute_val, inplace=True)\n",
      "C:\\Users\\JUANJO\\AppData\\Local\\Temp\\ipykernel_12244\\2626026109.py:18: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  is_categorical_dtype(df[col]) or\n",
      "C:\\Users\\JUANJO\\AppData\\Local\\Temp\\ipykernel_12244\\2626026109.py:78: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(impute_val, inplace=True)\n",
      "C:\\Users\\JUANJO\\AppData\\Local\\Temp\\ipykernel_12244\\2626026109.py:18: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  is_categorical_dtype(df[col]) or\n",
      "C:\\Users\\JUANJO\\AppData\\Local\\Temp\\ipykernel_12244\\2626026109.py:48: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(int(impute_val), inplace=True)\n",
      "C:\\Users\\JUANJO\\AppData\\Local\\Temp\\ipykernel_12244\\2626026109.py:18: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  is_categorical_dtype(df[col]) or\n",
      "C:\\Users\\JUANJO\\AppData\\Local\\Temp\\ipykernel_12244\\2626026109.py:78: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(impute_val, inplace=True)\n",
      "C:\\Users\\JUANJO\\AppData\\Local\\Temp\\ipykernel_12244\\2626026109.py:18: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  is_categorical_dtype(df[col]) or\n",
      "C:\\Users\\JUANJO\\AppData\\Local\\Temp\\ipykernel_12244\\2626026109.py:48: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(int(impute_val), inplace=True)\n",
      "C:\\Users\\JUANJO\\AppData\\Local\\Temp\\ipykernel_12244\\2626026109.py:18: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  is_categorical_dtype(df[col]) or\n",
      "C:\\Users\\JUANJO\\AppData\\Local\\Temp\\ipykernel_12244\\2626026109.py:48: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(int(impute_val), inplace=True)\n",
      "C:\\Users\\JUANJO\\AppData\\Local\\Temp\\ipykernel_12244\\2626026109.py:18: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  is_categorical_dtype(df[col]) or\n",
      "C:\\Users\\JUANJO\\AppData\\Local\\Temp\\ipykernel_12244\\2626026109.py:48: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(int(impute_val), inplace=True)\n",
      "C:\\Users\\JUANJO\\AppData\\Local\\Temp\\ipykernel_12244\\2626026109.py:18: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  is_categorical_dtype(df[col]) or\n",
      "C:\\Users\\JUANJO\\AppData\\Local\\Temp\\ipykernel_12244\\2626026109.py:48: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(int(impute_val), inplace=True)\n",
      "C:\\Users\\JUANJO\\AppData\\Local\\Temp\\ipykernel_12244\\2626026109.py:18: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  is_categorical_dtype(df[col]) or\n",
      "C:\\Users\\JUANJO\\AppData\\Local\\Temp\\ipykernel_12244\\2626026109.py:78: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(impute_val, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "fill_values = {}  # guardará la estrategia y el valor usado por columna\n",
    "\n",
    "# detectar si existe binary_maps (lo creaste antes); si no, lo ignoramos\n",
    "binary_map_keys = set(globals().get('binary_maps', {}).keys()) if 'binary_maps' in globals() else set()\n",
    "\n",
    "for col in df.columns:\n",
    "    # recuento de nulos actuales\n",
    "    n_null = df[col].isna().sum()\n",
    "    if n_null == 0:\n",
    "        continue  # nada que imputar\n",
    "\n",
    "    col_info = {}\n",
    "    # criterio para considerar \"categorica ordinal/binaria\":\n",
    "    # - dtype category OR\n",
    "    # - sufijo _ORD o _CATORD OR\n",
    "    # - columna presente en binary_maps\n",
    "    is_cat_ord = (\n",
    "        is_categorical_dtype(df[col]) or\n",
    "        str(col).endswith('_ORD') or\n",
    "        str(col).endswith('_CATORD') or\n",
    "        (col in binary_map_keys)\n",
    "    )\n",
    "\n",
    "    if is_cat_ord:\n",
    "        # usar moda (valor más frecuente)\n",
    "        try:\n",
    "            mode_series = df[col].mode(dropna=True)\n",
    "            if len(mode_series) > 0:\n",
    "                impute_val = mode_series.iloc[0]\n",
    "            else:\n",
    "                # si no hay moda (p. ej. todos NaN) -> dejar como NA (no imputamos)\n",
    "                impute_val = pd.NA\n",
    "        except Exception:\n",
    "            impute_val = pd.NA\n",
    "\n",
    "        # asignar inplace manteniendo dtype; para Int64 hacemos cast si es necesario\n",
    "        if pd.isna(impute_val):\n",
    "            # no hay valor para imputar -> saltar\n",
    "            col_info['strategy'] = 'mode'\n",
    "            col_info['value'] = None\n",
    "            fill_values[col] = col_info\n",
    "            continue\n",
    "\n",
    "        # Si la columna es Int64 o tenía ese tipo, convertir a Int64 tras fill\n",
    "        if df[col].dtype.name == 'Int64' or is_integer_dtype(df[col].dtype):\n",
    "            # impute_val puede ser numpy int, python int, or category\n",
    "            try:\n",
    "                df[col].fillna(int(impute_val), inplace=True)\n",
    "                df[col] = df[col].astype('Int64')\n",
    "                col_info['strategy'] = 'mode'\n",
    "                col_info['value'] = int(impute_val)\n",
    "            except Exception:\n",
    "                # en caso de fallo (p. ej. impute_val no convertible), usar raw fill\n",
    "                df[col].fillna(impute_val, inplace=True)\n",
    "                col_info['strategy'] = 'mode'\n",
    "                col_info['value'] = impute_val\n",
    "        else:\n",
    "            df[col].fillna(impute_val, inplace=True)\n",
    "            col_info['strategy'] = 'mode'\n",
    "            col_info['value'] = impute_val\n",
    "\n",
    "    else:\n",
    "        # tratar como numérica: imputar con la media\n",
    "        # si no es numérica, intentaremos convertirla; si falla, usaremos la moda como fallback\n",
    "        if is_numeric_dtype(df[col]):\n",
    "            mean_val = df[col].mean(skipna=True)\n",
    "            if pd.isna(mean_val):\n",
    "                # no hay datos numéricos -> fallback a moda\n",
    "                mode_series = df[col].mode(dropna=True)\n",
    "                impute_val = mode_series.iloc[0] if len(mode_series) > 0 else pd.NA\n",
    "                df[col].fillna(impute_val, inplace=True)\n",
    "                col_info['strategy'] = 'mode_fallback'\n",
    "                col_info['value'] = impute_val\n",
    "            else:\n",
    "                # si columna era entero nullable, redondeamos la media\n",
    "                if df[col].dtype.name == 'Int64' or is_integer_dtype(df[col].dtype):\n",
    "                    impute_val = int(round(mean_val))\n",
    "                    df[col].fillna(impute_val, inplace=True)\n",
    "                    df[col] = df[col].astype('Int64')\n",
    "                    col_info['strategy'] = 'mean_rounded'\n",
    "                    col_info['value'] = impute_val\n",
    "                else:\n",
    "                    df[col].fillna(mean_val, inplace=True)\n",
    "                    col_info['strategy'] = 'mean'\n",
    "                    col_info['value'] = float(mean_val)\n",
    "        else:\n",
    "            # no numérica; intentar convertir a numérico\n",
    "            coerced = pd.to_numeric(df[col], errors='coerce')\n",
    "            if coerced.notna().sum() > 0:\n",
    "                mean_val = coerced.mean(skipna=True)\n",
    "                impute_val = mean_val\n",
    "                # rellenar en la columna original (dejando tipo original) con el valor numérico\n",
    "                df[col] = df[col].fillna(impute_val)\n",
    "                col_info['strategy'] = 'mean_coerced'\n",
    "                col_info['value'] = float(impute_val)\n",
    "            else:\n",
    "                # fallback: usar la moda\n",
    "                mode_series = df[col].mode(dropna=True)\n",
    "                impute_val = mode_series.iloc[0] if len(mode_series) > 0 else pd.NA\n",
    "                df[col].fillna(impute_val, inplace=True)\n",
    "                col_info['strategy'] = 'mode_fallback_non_numeric'\n",
    "                col_info['value'] = impute_val\n",
    "\n",
    "    fill_values[col] = col_info\n",
    "\n",
    "# 4) Resumen final\n",
    "print(\"\\nResumen de imputaciones (columna: estrategia -> valor):\")\n",
    "for c, info in fill_values.items():\n",
    "    print(f\" - {c}: {info['strategy']} -> {info['value']}\")\n",
    "\n",
    "print(\"\\nComprobación rápida de nulos residuales por columna (debería ser 0 en la mayoría):\")\n",
    "print(df.isna().sum().sort_values(ascending=False).head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4a98d09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERIODO_ACADEMICO</th>\n",
       "      <th>E_VALORMATRICULAUNIVERSIDAD</th>\n",
       "      <th>E_HORASSEMANATRABAJA</th>\n",
       "      <th>F_ESTRATOVIVIENDA</th>\n",
       "      <th>F_TIENEINTERNET</th>\n",
       "      <th>F_EDUCACIONPADRE</th>\n",
       "      <th>F_TIENELAVADORA</th>\n",
       "      <th>F_TIENEAUTOMOVIL</th>\n",
       "      <th>E_PAGOMATRICULAPROPIO</th>\n",
       "      <th>F_TIENECOMPUTADOR</th>\n",
       "      <th>F_EDUCACIONMADRE</th>\n",
       "      <th>RENDIMIENTO_GLOBAL</th>\n",
       "      <th>INDICADOR_1</th>\n",
       "      <th>INDICADOR_2</th>\n",
       "      <th>INDICADOR_3</th>\n",
       "      <th>INDICADOR_4</th>\n",
       "      <th>RENDIMIENTO_GLOBAL_NUM</th>\n",
       "      <th>E_PRGM_ACADEMICO_ENC</th>\n",
       "      <th>E_PRGM_DEPARTAMENTO_ENC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20212</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>medio-alto</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.267</td>\n",
       "      <td>3</td>\n",
       "      <td>2.313951</td>\n",
       "      <td>2.557377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20212</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>bajo</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.264</td>\n",
       "      <td>1</td>\n",
       "      <td>2.629414</td>\n",
       "      <td>2.454803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20203</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>bajo</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.264</td>\n",
       "      <td>1</td>\n",
       "      <td>2.480084</td>\n",
       "      <td>2.557377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20195</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>alto</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.190</td>\n",
       "      <td>4</td>\n",
       "      <td>2.298893</td>\n",
       "      <td>2.734127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20212</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>medio-bajo</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.294</td>\n",
       "      <td>2</td>\n",
       "      <td>2.466328</td>\n",
       "      <td>2.667561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PERIODO_ACADEMICO  E_VALORMATRICULAUNIVERSIDAD  E_HORASSEMANATRABAJA  \\\n",
       "0              20212                            6                     1   \n",
       "1              20212                            4                     0   \n",
       "2              20203                            4                     4   \n",
       "3              20195                            5                     0   \n",
       "4              20212                            4                     3   \n",
       "\n",
       "   F_ESTRATOVIVIENDA  F_TIENEINTERNET  F_EDUCACIONPADRE  F_TIENELAVADORA  \\\n",
       "0                  3                0                 5                0   \n",
       "1                  3                1                 6                0   \n",
       "2                  3                0                 4                0   \n",
       "3                  4                0                 4                0   \n",
       "4                  3                0                 2                0   \n",
       "\n",
       "   F_TIENEAUTOMOVIL  E_PAGOMATRICULAPROPIO  F_TIENECOMPUTADOR  \\\n",
       "0                 0                      0                  0   \n",
       "1                 1                      0                  0   \n",
       "2                 1                      0                  1   \n",
       "3                 1                      0                  0   \n",
       "4                 0                      0                  0   \n",
       "\n",
       "   F_EDUCACIONMADRE RENDIMIENTO_GLOBAL  INDICADOR_1  INDICADOR_2  INDICADOR_3  \\\n",
       "0                 9         medio-alto        0.322        0.208        0.310   \n",
       "1                 5               bajo        0.311        0.215        0.292   \n",
       "2                 4               bajo        0.297        0.214        0.305   \n",
       "3                 4               alto        0.485        0.172        0.252   \n",
       "4                 2         medio-bajo        0.316        0.232        0.285   \n",
       "\n",
       "   INDICADOR_4  RENDIMIENTO_GLOBAL_NUM  E_PRGM_ACADEMICO_ENC  \\\n",
       "0        0.267                       3              2.313951   \n",
       "1        0.264                       1              2.629414   \n",
       "2        0.264                       1              2.480084   \n",
       "3        0.190                       4              2.298893   \n",
       "4        0.294                       2              2.466328   \n",
       "\n",
       "   E_PRGM_DEPARTAMENTO_ENC  \n",
       "0                 2.557377  \n",
       "1                 2.454803  \n",
       "2                 2.557377  \n",
       "3                 2.734127  \n",
       "4                 2.667561  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3354b69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#El número total de valores nulos en el DataFrame después del preprocesamiento\n",
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3a0462",
   "metadata": {},
   "source": [
    "\n",
    "### Normalización de Variables Numéricas\n",
    "\n",
    "En las celdas correspondientes, se realiza la normalización de las variables numéricas seleccionadas en el DataFrame `df`. Este proceso asegura que todas las variables estén en la misma escala, lo cual es importante para algoritmos de Machine Learning sensibles a las magnitudes de las variables. A continuación, se describe el procedimiento:\n",
    "\n",
    "1. **Selección de columnas a normalizar**:\n",
    "    - Se define una lista `cols_to_scale` con los nombres de las columnas que se desean normalizar.\n",
    "    - Se verifica la existencia de estas columnas en el DataFrame `df`. Si alguna columna no está presente, se omite y se emite una advertencia.\n",
    "\n",
    "2. **Conversión a tipo `float`**:\n",
    "    - Las columnas seleccionadas se convierten al tipo `float` para evitar problemas con valores nulos (`NA`) o tipos de datos como `Int64`.\n",
    "\n",
    "3. **Cálculo de parámetros de normalización**:\n",
    "    - Para cada columna, se calcula el valor mínimo (`mins`) y el valor máximo (`maxs`).\n",
    "    - Se calcula el denominador como la diferencia entre el máximo y el mínimo (`maxs - mins`). Si esta diferencia es 0 (cuando todos los valores son iguales), se reemplaza por 1 para evitar divisiones por cero.\n",
    "\n",
    "4. **Aplicación de la normalización**:\n",
    "    - Se utiliza la fórmula de normalización min-max:\n",
    "      \\[\n",
    "      X_{\\text{normalizado}} = \\frac{X - \\text{min}}{\\text{max} - \\text{min}}\n",
    "      \\]\n",
    "    - Esto transforma los valores de cada columna en un rango de 0 a 1.\n",
    "\n",
    "5. **Almacenamiento de parámetros de escala**:\n",
    "    - Los valores mínimos y máximos utilizados para cada columna se guardan en un diccionario `scale_params` para referencia futura.\n",
    "\n",
    "6. **Resumen post-normalización**:\n",
    "    - Se imprime un resumen de las columnas normalizadas, junto con los valores mínimos y máximos utilizados.\n",
    "    - También se verifica que los valores normalizados estén efectivamente en el rango [0, 1].\n",
    "\n",
    "Este enfoque asegura que las variables numéricas sean escaladas de manera consistente, preservando las relaciones relativas entre los valores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0e65b2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"PERIODO_ACADEMICO\"] = df[\"PERIODO_ACADEMICO\"].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "36c885a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas normalizadas (0-1): ['PERIODO_ACADEMICO', 'INDICADOR_1', 'INDICADOR_2', 'INDICADOR_3', 'INDICADOR_4', 'E_PRGM_ACADEMICO_ENC', 'E_PRGM_DEPARTAMENTO_ENC']\n",
      "\n",
      "Valores min/max usados:\n",
      " - PERIODO_ACADEMICO: min=20183.0, max=20213.0\n",
      " - INDICADOR_1: min=0.0, max=0.657\n",
      " - INDICADOR_2: min=0.0, max=0.487\n",
      " - INDICADOR_3: min=0.0, max=0.32\n",
      " - INDICADOR_4: min=0.0, max=0.332\n",
      " - E_PRGM_ACADEMICO_ENC: min=1.3466317257318603, max=3.745709920361281\n",
      " - E_PRGM_DEPARTAMENTO_ENC: min=1.369715606576111, max=2.930125698015135\n",
      "\n",
      "Resumen post-normalización (min, max) por columna (NaNs ignorados):\n",
      " - PERIODO_ACADEMICO: min=0.000000, max=1.000000\n",
      " - INDICADOR_1: min=0.000000, max=1.000000\n",
      " - INDICADOR_2: min=0.000000, max=1.000000\n",
      " - INDICADOR_3: min=0.000000, max=1.000000\n",
      " - INDICADOR_4: min=0.000000, max=1.000000\n",
      " - E_PRGM_ACADEMICO_ENC: min=0.000000, max=1.000000\n",
      " - E_PRGM_DEPARTAMENTO_ENC: min=0.000000, max=1.000000\n"
     ]
    }
   ],
   "source": [
    "cols_to_scale = [\n",
    "    'PERIODO_ACADEMICO',\n",
    "    'INDICADOR_1',\n",
    "    'INDICADOR_2',\n",
    "    'INDICADOR_3',\n",
    "    'INDICADOR_4',\n",
    "    'E_PRGM_ACADEMICO_ENC',\n",
    "    'E_PRGM_DEPARTAMENTO_ENC'\n",
    "]\n",
    "\n",
    "# comprobar existencia de columnas\n",
    "present = [c for c in cols_to_scale if c in df.columns]\n",
    "missing = [c for c in cols_to_scale if c not in df.columns]\n",
    "if missing:\n",
    "    print(\"Advertencia: las siguientes columnas no existen en df y serán omitidas:\", missing)\n",
    "\n",
    "if len(present) == 0:\n",
    "    print(\"No hay columnas válidas para normalizar. Revisa los nombres.\")\n",
    "else:\n",
    "    # convertir a float para evitar problemas con Int64/NA al calcular min/max\n",
    "    arr = df[present].astype(float)\n",
    "\n",
    "    mins = arr.min(skipna=True)\n",
    "    maxs = arr.max(skipna=True)\n",
    "    denom = (maxs - mins).replace(0, 1)  # evitar división por cero cuando max==min\n",
    "\n",
    "    df[present] = (arr - mins) / denom\n",
    "\n",
    "    # guardar parámetros de escala por si los necesitas luego\n",
    "    scale_params = {c: (float(mins[c]), float(maxs[c])) for c in present}\n",
    "\n",
    "    print(\"Columnas normalizadas (0-1):\", present)\n",
    "    print(\"\\nValores min/max usados:\")\n",
    "    for c in present:\n",
    "        print(f\" - {c}: min={scale_params[c][0]}, max={scale_params[c][1]}\")\n",
    "\n",
    "    # resumen rápido post-normalización\n",
    "    print(\"\\nResumen post-normalización (min, max) por columna (NaNs ignorados):\")\n",
    "    for c in present:\n",
    "        mn = df[c].min(skipna=True)\n",
    "        mx = df[c].max(skipna=True)\n",
    "        print(f\" - {c}: min={mn:.6f}, max={mx:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d8ef86",
   "metadata": {},
   "source": [
    "\n",
    "### Explicación de las últimas celdas del archivo\n",
    "\n",
    "En las últimas celdas del archivo, se realizan las siguientes operaciones:\n",
    "\n",
    "1. **Separación de la variable objetivo (`y`)**:\n",
    "    - En la celda 44, se extrae la columna `RENDIMIENTO_GLOBAL` del DataFrame `df` y se asigna a la variable `y`. Esta columna representa la variable objetivo del modelo.\n",
    "    - Posteriormente, se eliminan las columnas `RENDIMIENTO_GLOBAL` y `RENDIMIENTO_GLOBAL_NUM` del DataFrame `df`, dejando únicamente las características predictoras.\n",
    "\n",
    "2. **Codificación One-Hot de la variable objetivo (`y`)**:\n",
    "    - En la celda 45, se utiliza la clase `OneHotEncoder` de `sklearn` para realizar una codificación One-Hot de la variable `y`. Esto transforma las categorías de `RENDIMIENTO_GLOBAL` en un formato binario, donde cada categoría se representa como una columna con valores 0 o 1.\n",
    "    - El resultado se almacena en la variable `y_one_hot`, que es una matriz dispersa (`sparse matrix`) para optimizar el uso de memoria.\n",
    "\n",
    "3. **Conversión de la matriz dispersa a un DataFrame**:\n",
    "    - En la celda 46, la matriz dispersa `y_one_hot` se convierte en un DataFrame utilizando `pd.DataFrame.sparse.from_spmatrix`. Las columnas del DataFrame resultante se nombran utilizando los nombres de las categorías generados por `OneHotEncoder`.\n",
    "\n",
    "4. **Visualización de los datos**:\n",
    "    - En la celda 47, se utiliza `df.head()` para mostrar las primeras filas del DataFrame `df`, permitiendo verificar el estado de las características después del preprocesamiento.\n",
    "\n",
    "5. **Copia del DataFrame de características (`X`)**:\n",
    "    - En la celda 48, se realiza una copia del DataFrame `df` y se asigna a la variable `X`. Esto asegura que `X` contenga únicamente las características predictoras, separadas de la variable objetivo.\n",
    "\n",
    "6. **Guardado de los conjuntos preprocesados**:\n",
    "    - En la celda 49, se guardan los conjuntos preprocesados `X` y `y` en archivos CSV (`X_preprocessed.csv` y `y_preprocessed.csv`) para su uso posterior.\n",
    "    - En la celda 50, se guarda el DataFrame `y_df` (resultado de la codificación One-Hot) en un archivo CSV (`y_one_hot_preprocessed.csv`).\n",
    "\n",
    "Estas celdas finalizan el preprocesamiento de los datos, dejando los conjuntos de características (`X`) y la variable objetivo (`y`) listos para ser utilizados en el entrenamiento de modelos de Machine Learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f130a1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['RENDIMIENTO_GLOBAL']\n",
    "df.drop(columns=['RENDIMIENTO_GLOBAL', 'RENDIMIENTO_GLOBAL_NUM'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "69c3bc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding del target con sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "y_one_hot = OneHotEncoder().fit_transform(y.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f6af2575",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.DataFrame.sparse.from_spmatrix(y_one_hot, columns=OneHotEncoder().fit(y.values.reshape(-1, 1)).get_feature_names_out(['RENDIMIENTO_GLOBAL']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7c0e550b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERIODO_ACADEMICO</th>\n",
       "      <th>E_VALORMATRICULAUNIVERSIDAD</th>\n",
       "      <th>E_HORASSEMANATRABAJA</th>\n",
       "      <th>F_ESTRATOVIVIENDA</th>\n",
       "      <th>F_TIENEINTERNET</th>\n",
       "      <th>F_EDUCACIONPADRE</th>\n",
       "      <th>F_TIENELAVADORA</th>\n",
       "      <th>F_TIENEAUTOMOVIL</th>\n",
       "      <th>E_PAGOMATRICULAPROPIO</th>\n",
       "      <th>F_TIENECOMPUTADOR</th>\n",
       "      <th>F_EDUCACIONMADRE</th>\n",
       "      <th>INDICADOR_1</th>\n",
       "      <th>INDICADOR_2</th>\n",
       "      <th>INDICADOR_3</th>\n",
       "      <th>INDICADOR_4</th>\n",
       "      <th>E_PRGM_ACADEMICO_ENC</th>\n",
       "      <th>E_PRGM_DEPARTAMENTO_ENC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.490107</td>\n",
       "      <td>0.427105</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.804217</td>\n",
       "      <td>0.403205</td>\n",
       "      <td>0.761121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.473364</td>\n",
       "      <td>0.441478</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.795181</td>\n",
       "      <td>0.534698</td>\n",
       "      <td>0.695386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.439425</td>\n",
       "      <td>0.953125</td>\n",
       "      <td>0.795181</td>\n",
       "      <td>0.472453</td>\n",
       "      <td>0.761121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.738204</td>\n",
       "      <td>0.353183</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.572289</td>\n",
       "      <td>0.396928</td>\n",
       "      <td>0.874393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.480974</td>\n",
       "      <td>0.476386</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.885542</td>\n",
       "      <td>0.466719</td>\n",
       "      <td>0.831733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PERIODO_ACADEMICO  E_VALORMATRICULAUNIVERSIDAD  E_HORASSEMANATRABAJA  \\\n",
       "0           0.966667                            6                     1   \n",
       "1           0.966667                            4                     0   \n",
       "2           0.666667                            4                     4   \n",
       "3           0.400000                            5                     0   \n",
       "4           0.966667                            4                     3   \n",
       "\n",
       "   F_ESTRATOVIVIENDA  F_TIENEINTERNET  F_EDUCACIONPADRE  F_TIENELAVADORA  \\\n",
       "0                  3                0                 5                0   \n",
       "1                  3                1                 6                0   \n",
       "2                  3                0                 4                0   \n",
       "3                  4                0                 4                0   \n",
       "4                  3                0                 2                0   \n",
       "\n",
       "   F_TIENEAUTOMOVIL  E_PAGOMATRICULAPROPIO  F_TIENECOMPUTADOR  \\\n",
       "0                 0                      0                  0   \n",
       "1                 1                      0                  0   \n",
       "2                 1                      0                  1   \n",
       "3                 1                      0                  0   \n",
       "4                 0                      0                  0   \n",
       "\n",
       "   F_EDUCACIONMADRE  INDICADOR_1  INDICADOR_2  INDICADOR_3  INDICADOR_4  \\\n",
       "0                 9     0.490107     0.427105     0.968750     0.804217   \n",
       "1                 5     0.473364     0.441478     0.912500     0.795181   \n",
       "2                 4     0.452055     0.439425     0.953125     0.795181   \n",
       "3                 4     0.738204     0.353183     0.787500     0.572289   \n",
       "4                 2     0.480974     0.476386     0.890625     0.885542   \n",
       "\n",
       "   E_PRGM_ACADEMICO_ENC  E_PRGM_DEPARTAMENTO_ENC  \n",
       "0              0.403205                 0.761121  \n",
       "1              0.534698                 0.695386  \n",
       "2              0.472453                 0.761121  \n",
       "3              0.396928                 0.874393  \n",
       "4              0.466719                 0.831733  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "212c6abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728f04dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar los conjuntos preprocesados\n",
    "X.to_csv('data/X_preprocessed.csv', index=False)\n",
    "y.to_csv('data/y_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e1699587",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df.to_csv('data/y_one_hot_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef5dff2",
   "metadata": {},
   "source": [
    "### Conclusión del Preprocesamiento de Datos\n",
    "\n",
    "El preprocesamiento realizado en este archivo ha permitido transformar y preparar un conjunto de datos extenso y complejo para su uso en modelos de Machine Learning. A continuación, se resumen los puntos clave:\n",
    "\n",
    "1. **Limpieza y Transformación de Datos**:\n",
    "    - Se eliminaron columnas redundantes o irrelevantes, como `ID`, `E_PRIVADO_LIBERTAD`, y `F_TIENEINTERNET.1`.\n",
    "    - Se imputaron valores nulos utilizando estrategias específicas para cada tipo de variable (moda para categóricas y media para numéricas).\n",
    "    - Se normalizaron las variables numéricas seleccionadas, asegurando que todas estén en la misma escala (rango [0, 1]).\n",
    "\n",
    "2. **Codificación de Variables Categóricas**:\n",
    "    - Se aplicaron técnicas de codificación como el encoding ordinal y el encoding suavizado para variables categóricas, como `E_PRGM_ACADEMICO` y `E_PRGM_DEPARTAMENTO`.\n",
    "    - Las variables binarias fueron transformadas a valores numéricos (0 y 1), preservando valores nulos cuando fue necesario.\n",
    "    - La variable objetivo `RENDIMIENTO_GLOBAL` fue transformada a una representación ordinal y también se realizó una codificación One-Hot para su uso en diferentes modelos.\n",
    "\n",
    "3. **Análisis de Independencia y Relación**:\n",
    "    - Se realizaron pruebas de Chi-cuadrado para evaluar la independencia entre variables categóricas y la variable objetivo, identificando relaciones significativas.\n",
    "\n",
    "4. **Preparación de Conjuntos de Datos**:\n",
    "    - Se separaron las características predictoras (`X`) y la variable objetivo (`y`), asegurando que los datos estén listos para el entrenamiento de modelos.\n",
    "    - Los conjuntos preprocesados fueron guardados en archivos CSV para su uso posterior.\n",
    "\n",
    "5. **Escalabilidad y Eficiencia**:\n",
    "    - El preprocesamiento fue diseñado para manejar un conjunto de datos grande (690,861 registros), optimizando el uso de memoria y preservando la integridad de los datos.\n",
    "\n",
    "En general, este archivo demuestra un flujo de trabajo robusto y bien documentado para el preprocesamiento de datos, asegurando que el conjunto de datos esté limpio, transformado y listo para ser utilizado en tareas de modelado predictivo. Este enfoque garantiza que los modelos puedan aprovechar al máximo la información contenida en los datos, minimizando el impacto de valores atípicos, nulos o inconsistencias."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
